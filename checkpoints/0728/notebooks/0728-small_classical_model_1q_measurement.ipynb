{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('peptide-QML/')\n",
    "\n",
    "from my_code import functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'peptide-QML/data/energies/PET/generated/bb14_Strings_Energies_10_000_4_aa.txt'  # Replace with the actual path to your 'data.txt' file\n",
    "string_list, number_list = f.read_data_file(file_path)\n",
    "score_list = np.array(number_list)/100\n",
    "vector_list = np.array([f.string_to_vector(string) for string in string_list]) # one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_aminoacids = len(string_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_validation, Y_validation = f.create_validating_set(vector_list, score_list, percentage=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1]*X.shape[2]) # flatten\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], X_validation.shape[1]*X_validation.shape[2]) # flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "input_data = torch.tensor(X, dtype=torch.float32)\n",
    "target_data = torch.tensor(Y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Define the validation set\n",
    "input_validation = torch.tensor(X_validation, dtype=torch.float32)\n",
    "target_validation = torch.tensor(Y_validation, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = input_data.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pre_classical_layers = 4\n",
    "layers_dim = np.linspace(4, input_dim, 4).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "for i in range(1, len(layers_dim)):\n",
    "    layers += [nn.Linear(layers_dim[-1*i], layers_dim[-1*(i+1)]), nn.ReLU()]\n",
    "layers += [nn.Linear(layers_dim[0], layers_dim[0])]\n",
    "layers += [nn.Linear(layers_dim[0], 1)]\n",
    "\n",
    "\n",
    "Net = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the network\n",
    "model = Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/25], Loss: 2.0451, Loss validation: 2.9102\n",
      "- Epoch [1/25], i: [4992/9000], Loss: 0.0337\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.1812, Loss validation: 0.0773, Time remaining: ~0.0h 0.0m 11s\n",
      "Epoch [2/25], Loss: 0.0435, Loss validation: 0.0455, Time remaining: ~0.0h 0.0m 9s\n",
      "Epoch [3/25], Loss: 0.0136, Loss validation: 0.0143, Time remaining: ~0.0h 0.0m 8s\n",
      "Epoch [4/25], Loss: 0.0119, Loss validation: 0.0058, Time remaining: ~0.0h 0.0m 8s\n",
      "Epoch [5/25], Loss: 0.0140, Loss validation: 0.0228, Time remaining: ~0.0h 0.0m 7s\n",
      "Epoch [6/25], Loss: 0.0129, Loss validation: 0.0100, Time remaining: ~0.0h 0.0m 7s\n",
      "Epoch [7/25], Loss: 0.0171, Loss validation: 0.2052, Time remaining: ~0.0h 0.0m 6s\n",
      "Epoch [8/25], Loss: 0.0756, Loss validation: 0.0253, Time remaining: ~0.0h 0.0m 6s\n",
      "Epoch [9/25], Loss: 0.0150, Loss validation: 0.0114, Time remaining: ~0.0h 0.0m 5s\n",
      "Epoch [10/25], Loss: 0.0074, Loss validation: 0.0092, Time remaining: ~0.0h 0.0m 5s\n",
      "Epoch [11/25], Loss: 0.0055, Loss validation: 0.0072, Time remaining: ~0.0h 0.0m 5s\n",
      "Epoch [12/25], Loss: 0.0085, Loss validation: 0.0084, Time remaining: ~0.0h 0.0m 4s\n",
      "Epoch [13/25], Loss: 0.0089, Loss validation: 0.0227, Time remaining: ~0.0h 0.0m 4s\n",
      "Epoch [14/25], Loss: 0.0187, Loss validation: 0.0170, Time remaining: ~0.0h 0.0m 4s\n",
      "Epoch [15/25], Loss: 0.0121, Loss validation: 0.0094, Time remaining: ~0.0h 0.0m 3s\n",
      "Epoch [16/25], Loss: 0.0094, Loss validation: 0.0073, Time remaining: ~0.0h 0.0m 3s\n",
      "Epoch [17/25], Loss: 0.0060, Loss validation: 0.0101, Time remaining: ~0.0h 0.0m 3s\n",
      "Epoch [18/25], Loss: 0.0391, Loss validation: 0.1063, Time remaining: ~0.0h 0.0m 2s\n",
      "Epoch [19/25], Loss: 0.0297, Loss validation: 0.0431, Time remaining: ~0.0h 0.0m 2s\n",
      "Epoch [20/25], Loss: 0.0201, Loss validation: 0.0110, Time remaining: ~0.0h 0.0m 2s\n",
      "Epoch [21/25], Loss: 0.0085, Loss validation: 0.0047, Time remaining: ~0.0h 0.0m 1s\n",
      "Epoch [22/25], Loss: 0.0043, Loss validation: 0.0064, Time remaining: ~0.0h 0.0m 1s\n",
      "Epoch [23/25], Loss: 0.0051, Loss validation: 0.0049, Time remaining: ~0.0h 0.0m 1s\n",
      "Epoch [24/25], Loss: 0.0066, Loss validation: 0.0083, Time remaining: ~0.0h 0.0m 0s\n",
      "Epoch [25/25], Loss: 0.0056, Loss validation: 0.0119, Time remaining: ~0.0h 0.0m 0s\n"
     ]
    }
   ],
   "source": [
    "# time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)  # Adam optimizer with learning rate 0.001\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "#validation data\n",
    "i_validation = input_validation[::10] #we take only 10% of the validation data, to speed up the process\n",
    "t_validation = target_validation[::10] \n",
    "\n",
    "losses = []\n",
    "losses_epochs = [0]\n",
    "losses_epochs_validation = [0]\n",
    "\n",
    "losses_epochs[-1] = criterion(model(input_data), target_data).item()\n",
    "losses_epochs_validation[-1] = criterion(model(i_validation), t_validation).item()\n",
    "print('Epoch [{}/{}], Loss: {:.4f}, Loss validation: {:.4f}'.format(0, num_epochs, losses_epochs[-1], losses_epochs_validation[-1]))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the dataset\n",
    "    indices = torch.randperm(input_data.size(0))\n",
    "    input_data = input_data[indices]\n",
    "    target_data = target_data[indices]\n",
    "\n",
    "    losses_epochs.append(0)\n",
    "\n",
    "    # Mini-batch training\n",
    "    for i in range(0, input_data.size(0), batch_size):\n",
    "        inputs = input_data[i:i+batch_size]\n",
    "        targets = target_data[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        print('- Epoch [{}/{}], i: [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i, input_data.size(0), loss.item()), end='\\r')\n",
    "\n",
    "        # add to the epoch loss\n",
    "        losses_epochs[-1] += loss.item() \n",
    "\n",
    "    # divide the epoch loss by the number of batches, to get the average loss\n",
    "    losses_epochs[-1] /= (input_data.size(0)/batch_size)\n",
    "\n",
    "    # Validation\n",
    "    losses_epochs_validation.append(criterion(model(i_validation), t_validation).item())    \n",
    "\n",
    "    # time\n",
    "    # Compute elapsed time and remaining time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    avg_time_per_epoch = elapsed_time / (epoch + 1)\n",
    "    remaining_epochs = num_epochs - (epoch + 1)\n",
    "    estimated_remaining_time = avg_time_per_epoch * remaining_epochs\n",
    "\n",
    "    # Convert remaining time to hours, minutes, and seconds for better readability\n",
    "    hours, remainder = divmod(estimated_remaining_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    # Print the loss and remaining time for this epoch\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Loss validation: {:.4f}, Time remaining: ~{}h {}m {:.0f}s'.format(\n",
    "        epoch+1, num_epochs, losses_epochs[-1], losses_epochs_validation[-1], hours, minutes, seconds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses_epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, \t target: 1.640, \t output: 1.655, \t loss: 0.000\n",
      "i: 1, \t target: 4.086, \t output: 4.079, \t loss: 0.000\n",
      "i: 2, \t target: 1.949, \t output: 1.954, \t loss: 0.000\n",
      "i: 3, \t target: -0.406, \t output: -0.272, \t loss: 0.018\n",
      "i: 4, \t target: 1.846, \t output: 1.795, \t loss: 0.003\n",
      "i: 5, \t target: -0.773, \t output: -0.793, \t loss: 0.000\n",
      "i: 6, \t target: 0.433, \t output: 0.354, \t loss: 0.006\n",
      "i: 7, \t target: 1.709, \t output: 1.818, \t loss: 0.012\n",
      "i: 8, \t target: -0.465, \t output: -0.495, \t loss: 0.001\n",
      "i: 9, \t target: 3.100, \t output: 3.228, \t loss: 0.016\n",
      "i: 10, \t target: 0.625, \t output: 0.593, \t loss: 0.001\n",
      "i: 11, \t target: -0.522, \t output: -0.585, \t loss: 0.004\n",
      "i: 12, \t target: -0.760, \t output: -0.809, \t loss: 0.002\n",
      "i: 13, \t target: -0.563, \t output: -0.620, \t loss: 0.003\n",
      "i: 14, \t target: 2.350, \t output: 2.392, \t loss: 0.002\n",
      "i: 15, \t target: 1.913, \t output: 2.008, \t loss: 0.009\n",
      "i: 16, \t target: 0.525, \t output: 0.476, \t loss: 0.002\n",
      "i: 17, \t target: -0.377, \t output: -0.418, \t loss: 0.002\n",
      "i: 18, \t target: -0.903, \t output: -0.865, \t loss: 0.001\n",
      "i: 19, \t target: -0.527, \t output: -0.576, \t loss: 0.002\n",
      "i: 20, \t target: 1.924, \t output: 1.811, \t loss: 0.013\n",
      "i: 21, \t target: -0.791, \t output: -0.854, \t loss: 0.004\n",
      "i: 22, \t target: 2.728, \t output: 2.747, \t loss: 0.000\n",
      "i: 23, \t target: 3.034, \t output: 2.872, \t loss: 0.026\n",
      "i: 24, \t target: -0.801, \t output: -0.810, \t loss: 0.000\n",
      "i: 25, \t target: 1.665, \t output: 1.654, \t loss: 0.000\n",
      "i: 26, \t target: 2.938, \t output: 2.781, \t loss: 0.025\n",
      "i: 27, \t target: 1.794, \t output: 1.811, \t loss: 0.000\n",
      "i: 28, \t target: 0.964, \t output: 0.952, \t loss: 0.000\n",
      "i: 29, \t target: 2.098, \t output: 2.039, \t loss: 0.004\n",
      "i: 30, \t target: -0.671, \t output: -0.730, \t loss: 0.003\n",
      "i: 31, \t target: 2.021, \t output: 1.942, \t loss: 0.006\n",
      "i: 32, \t target: 1.016, \t output: 1.048, \t loss: 0.001\n",
      "i: 33, \t target: 2.265, \t output: 2.403, \t loss: 0.019\n",
      "i: 34, \t target: -0.422, \t output: -0.455, \t loss: 0.001\n",
      "i: 35, \t target: 0.038, \t output: 0.089, \t loss: 0.003\n",
      "i: 36, \t target: -0.733, \t output: -0.754, \t loss: 0.000\n",
      "i: 37, \t target: -0.629, \t output: -0.703, \t loss: 0.006\n",
      "i: 38, \t target: -0.748, \t output: -0.776, \t loss: 0.001\n",
      "i: 39, \t target: -0.765, \t output: -0.808, \t loss: 0.002\n",
      "i: 40, \t target: -0.718, \t output: -0.793, \t loss: 0.006\n",
      "i: 41, \t target: 2.753, \t output: 2.633, \t loss: 0.014\n",
      "i: 42, \t target: 0.945, \t output: 0.974, \t loss: 0.001\n",
      "i: 43, \t target: 1.693, \t output: 1.760, \t loss: 0.004\n",
      "i: 44, \t target: 0.708, \t output: 0.739, \t loss: 0.001\n",
      "i: 45, \t target: 1.979, \t output: 2.043, \t loss: 0.004\n",
      "i: 46, \t target: -1.000, \t output: -1.087, \t loss: 0.008\n",
      "i: 47, \t target: 1.759, \t output: 1.719, \t loss: 0.002\n",
      "i: 48, \t target: -0.823, \t output: -0.866, \t loss: 0.002\n",
      "i: 49, \t target: 2.145, \t output: 2.183, \t loss: 0.001\n",
      "i: 50, \t target: -0.603, \t output: -0.615, \t loss: 0.000\n",
      "i: 51, \t target: 2.001, \t output: 2.042, \t loss: 0.002\n",
      "i: 52, \t target: 0.183, \t output: 0.130, \t loss: 0.003\n",
      "i: 53, \t target: 1.439, \t output: 1.435, \t loss: 0.000\n",
      "i: 54, \t target: -0.526, \t output: -0.491, \t loss: 0.001\n",
      "i: 55, \t target: -0.615, \t output: -0.697, \t loss: 0.007\n",
      "i: 56, \t target: -0.067, \t output: -0.061, \t loss: 0.000\n",
      "i: 57, \t target: 1.754, \t output: 1.727, \t loss: 0.001\n",
      "i: 58, \t target: 1.351, \t output: 1.284, \t loss: 0.004\n",
      "i: 59, \t target: 1.637, \t output: 1.699, \t loss: 0.004\n",
      "i: 60, \t target: -0.296, \t output: -0.343, \t loss: 0.002\n",
      "i: 61, \t target: 1.544, \t output: 1.565, \t loss: 0.000\n",
      "i: 62, \t target: -0.779, \t output: -0.840, \t loss: 0.004\n",
      "i: 63, \t target: 0.316, \t output: 0.330, \t loss: 0.000\n",
      "i: 64, \t target: 0.280, \t output: 0.285, \t loss: 0.000\n",
      "i: 65, \t target: -0.303, \t output: -0.283, \t loss: 0.000\n",
      "i: 66, \t target: 0.844, \t output: 0.922, \t loss: 0.006\n",
      "i: 67, \t target: -0.615, \t output: -0.680, \t loss: 0.004\n",
      "i: 68, \t target: 0.326, \t output: 0.340, \t loss: 0.000\n",
      "i: 69, \t target: 0.467, \t output: 0.439, \t loss: 0.001\n",
      "i: 70, \t target: -0.641, \t output: -0.690, \t loss: 0.002\n",
      "i: 71, \t target: -0.665, \t output: -0.704, \t loss: 0.002\n",
      "i: 72, \t target: -0.755, \t output: -0.782, \t loss: 0.001\n",
      "i: 73, \t target: 0.391, \t output: 0.380, \t loss: 0.000\n",
      "i: 74, \t target: -0.859, \t output: -0.965, \t loss: 0.011\n",
      "i: 75, \t target: -0.742, \t output: -0.856, \t loss: 0.013\n",
      "i: 76, \t target: -0.275, \t output: -0.277, \t loss: 0.000\n",
      "i: 77, \t target: 1.299, \t output: 1.295, \t loss: 0.000\n",
      "i: 78, \t target: -0.982, \t output: -1.032, \t loss: 0.003\n",
      "i: 79, \t target: 2.053, \t output: 2.069, \t loss: 0.000\n",
      "i: 80, \t target: 0.868, \t output: 0.863, \t loss: 0.000\n",
      "i: 81, \t target: 1.101, \t output: 1.159, \t loss: 0.003\n",
      "i: 82, \t target: 1.778, \t output: 1.757, \t loss: 0.000\n",
      "i: 83, \t target: -0.713, \t output: -0.756, \t loss: 0.002\n",
      "i: 84, \t target: -0.730, \t output: -0.783, \t loss: 0.003\n",
      "i: 85, \t target: 1.937, \t output: 1.991, \t loss: 0.003\n",
      "i: 86, \t target: -1.019, \t output: -1.076, \t loss: 0.003\n",
      "i: 87, \t target: 1.958, \t output: 1.959, \t loss: 0.000\n",
      "i: 88, \t target: 4.616, \t output: 4.683, \t loss: 0.004\n",
      "i: 89, \t target: 1.859, \t output: 1.807, \t loss: 0.003\n",
      "i: 90, \t target: 1.066, \t output: 1.220, \t loss: 0.024\n",
      "i: 91, \t target: -0.751, \t output: -0.796, \t loss: 0.002\n",
      "i: 92, \t target: -0.439, \t output: -0.469, \t loss: 0.001\n",
      "i: 93, \t target: 4.230, \t output: 4.469, \t loss: 0.057\n",
      "i: 94, \t target: 1.936, \t output: 1.889, \t loss: 0.002\n",
      "i: 95, \t target: -0.890, \t output: -0.967, \t loss: 0.006\n",
      "i: 96, \t target: 0.446, \t output: 0.440, \t loss: 0.000\n",
      "i: 97, \t target: 0.129, \t output: 0.086, \t loss: 0.002\n",
      "i: 98, \t target: -0.310, \t output: -0.256, \t loss: 0.003\n",
      "i: 99, \t target: -0.960, \t output: -0.996, \t loss: 0.001\n",
      "i: 100, \t target: 1.655, \t output: 1.781, \t loss: 0.016\n",
      "i: 101, \t target: -0.653, \t output: -0.693, \t loss: 0.002\n",
      "i: 102, \t target: -0.600, \t output: -0.652, \t loss: 0.003\n",
      "i: 103, \t target: 4.930, \t output: 5.102, \t loss: 0.030\n",
      "i: 104, \t target: -0.602, \t output: -0.668, \t loss: 0.004\n",
      "i: 105, \t target: -0.809, \t output: -0.903, \t loss: 0.009\n",
      "i: 106, \t target: -0.528, \t output: -0.465, \t loss: 0.004\n",
      "i: 107, \t target: -0.840, \t output: -0.874, \t loss: 0.001\n",
      "i: 108, \t target: 2.025, \t output: 2.034, \t loss: 0.000\n",
      "i: 109, \t target: -0.632, \t output: -0.664, \t loss: 0.001\n",
      "i: 110, \t target: -0.732, \t output: -0.765, \t loss: 0.001\n",
      "i: 111, \t target: 0.409, \t output: 0.363, \t loss: 0.002\n",
      "i: 112, \t target: -0.095, \t output: -0.104, \t loss: 0.000\n",
      "i: 113, \t target: -0.686, \t output: -0.732, \t loss: 0.002\n",
      "i: 114, \t target: -0.730, \t output: -0.778, \t loss: 0.002\n",
      "i: 115, \t target: 1.575, \t output: 1.702, \t loss: 0.016\n",
      "i: 116, \t target: 0.306, \t output: 0.391, \t loss: 0.007\n",
      "i: 117, \t target: 1.619, \t output: 1.579, \t loss: 0.002\n",
      "i: 118, \t target: -0.308, \t output: -0.369, \t loss: 0.004\n",
      "i: 119, \t target: -0.002, \t output: 0.014, \t loss: 0.000\n",
      "i: 120, \t target: -0.784, \t output: -0.856, \t loss: 0.005\n",
      "i: 121, \t target: 3.226, \t output: 3.212, \t loss: 0.000\n",
      "i: 122, \t target: 2.039, \t output: 2.035, \t loss: 0.000\n",
      "i: 123, \t target: -0.490, \t output: -0.481, \t loss: 0.000\n",
      "i: 124, \t target: 3.958, \t output: 4.292, \t loss: 0.112\n",
      "i: 125, \t target: -0.631, \t output: -0.656, \t loss: 0.001\n",
      "i: 126, \t target: 0.319, \t output: 0.355, \t loss: 0.001\n",
      "i: 127, \t target: -0.578, \t output: -0.592, \t loss: 0.000\n",
      "i: 128, \t target: -1.008, \t output: -1.082, \t loss: 0.005\n",
      "i: 129, \t target: -0.896, \t output: -0.869, \t loss: 0.001\n",
      "i: 130, \t target: 0.899, \t output: 0.900, \t loss: 0.000\n",
      "i: 131, \t target: 1.414, \t output: 1.454, \t loss: 0.002\n",
      "i: 132, \t target: -0.170, \t output: -0.217, \t loss: 0.002\n",
      "i: 133, \t target: 0.548, \t output: 0.368, \t loss: 0.033\n",
      "i: 134, \t target: -0.727, \t output: -0.761, \t loss: 0.001\n",
      "i: 135, \t target: 0.665, \t output: 0.640, \t loss: 0.001\n",
      "i: 136, \t target: -0.668, \t output: -0.677, \t loss: 0.000\n",
      "i: 137, \t target: 0.589, \t output: 0.582, \t loss: 0.000\n",
      "i: 138, \t target: 1.547, \t output: 1.590, \t loss: 0.002\n",
      "i: 139, \t target: -0.885, \t output: -0.939, \t loss: 0.003\n",
      "i: 140, \t target: -0.692, \t output: -0.721, \t loss: 0.001\n",
      "i: 141, \t target: 1.879, \t output: 1.875, \t loss: 0.000\n",
      "i: 142, \t target: 0.987, \t output: 0.957, \t loss: 0.001\n",
      "i: 143, \t target: 1.612, \t output: 1.589, \t loss: 0.001\n",
      "i: 144, \t target: -0.794, \t output: -0.825, \t loss: 0.001\n",
      "i: 145, \t target: -0.326, \t output: -0.340, \t loss: 0.000\n",
      "i: 146, \t target: -1.222, \t output: -1.267, \t loss: 0.002\n",
      "i: 147, \t target: 1.216, \t output: 1.183, \t loss: 0.001\n",
      "i: 148, \t target: -0.414, \t output: -0.465, \t loss: 0.003\n",
      "i: 149, \t target: -0.394, \t output: -0.448, \t loss: 0.003\n",
      "i: 150, \t target: -0.588, \t output: -0.662, \t loss: 0.006\n",
      "i: 151, \t target: -0.607, \t output: -0.660, \t loss: 0.003\n",
      "i: 152, \t target: 1.107, \t output: 1.179, \t loss: 0.005\n",
      "i: 153, \t target: 2.262, \t output: 2.380, \t loss: 0.014\n",
      "i: 154, \t target: -0.584, \t output: -0.639, \t loss: 0.003\n",
      "i: 155, \t target: -0.733, \t output: -0.784, \t loss: 0.003\n",
      "i: 156, \t target: 0.717, \t output: 0.739, \t loss: 0.000\n",
      "i: 157, \t target: -0.800, \t output: -0.898, \t loss: 0.010\n",
      "i: 158, \t target: 0.353, \t output: 0.319, \t loss: 0.001\n",
      "i: 159, \t target: -0.503, \t output: -0.559, \t loss: 0.003\n",
      "i: 160, \t target: 4.772, \t output: 4.956, \t loss: 0.034\n",
      "i: 161, \t target: 1.794, \t output: 1.974, \t loss: 0.032\n",
      "i: 162, \t target: -0.292, \t output: -0.248, \t loss: 0.002\n",
      "i: 163, \t target: -0.693, \t output: -0.738, \t loss: 0.002\n",
      "i: 164, \t target: 0.333, \t output: 0.351, \t loss: 0.000\n",
      "i: 165, \t target: -0.577, \t output: -0.657, \t loss: 0.007\n",
      "i: 166, \t target: -0.821, \t output: -0.842, \t loss: 0.000\n",
      "i: 167, \t target: 1.885, \t output: 1.872, \t loss: 0.000\n",
      "i: 168, \t target: 0.351, \t output: 0.251, \t loss: 0.010\n",
      "i: 169, \t target: -0.540, \t output: -0.599, \t loss: 0.003\n",
      "i: 170, \t target: 0.694, \t output: 0.713, \t loss: 0.000\n",
      "i: 171, \t target: -0.718, \t output: -0.789, \t loss: 0.005\n",
      "i: 172, \t target: 1.271, \t output: 1.362, \t loss: 0.008\n",
      "i: 173, \t target: -0.748, \t output: -0.730, \t loss: 0.000\n",
      "i: 174, \t target: 0.954, \t output: 0.972, \t loss: 0.000\n",
      "i: 175, \t target: -0.674, \t output: -0.717, \t loss: 0.002\n",
      "i: 176, \t target: -0.779, \t output: -0.842, \t loss: 0.004\n",
      "i: 177, \t target: 0.738, \t output: 0.778, \t loss: 0.002\n",
      "i: 178, \t target: -0.538, \t output: -0.540, \t loss: 0.000\n",
      "i: 179, \t target: 1.609, \t output: 1.697, \t loss: 0.008\n",
      "i: 180, \t target: 0.088, \t output: 0.059, \t loss: 0.001\n",
      "i: 181, \t target: -0.817, \t output: -0.873, \t loss: 0.003\n",
      "i: 182, \t target: 2.197, \t output: 2.285, \t loss: 0.008\n",
      "i: 183, \t target: 1.754, \t output: 1.747, \t loss: 0.000\n",
      "i: 184, \t target: -0.927, \t output: -1.022, \t loss: 0.009\n",
      "i: 185, \t target: -1.137, \t output: -1.186, \t loss: 0.002\n",
      "i: 186, \t target: -0.702, \t output: -0.714, \t loss: 0.000\n",
      "i: 187, \t target: 2.307, \t output: 2.305, \t loss: 0.000\n",
      "i: 188, \t target: -0.668, \t output: -0.712, \t loss: 0.002\n",
      "i: 189, \t target: 0.655, \t output: 0.594, \t loss: 0.004\n",
      "i: 190, \t target: -0.687, \t output: -0.741, \t loss: 0.003\n",
      "i: 191, \t target: -0.350, \t output: -0.363, \t loss: 0.000\n",
      "i: 192, \t target: -0.869, \t output: -0.949, \t loss: 0.006\n",
      "i: 193, \t target: -0.620, \t output: -0.670, \t loss: 0.003\n",
      "i: 194, \t target: 0.137, \t output: 0.144, \t loss: 0.000\n",
      "i: 195, \t target: -0.872, \t output: -0.966, \t loss: 0.009\n",
      "i: 196, \t target: -0.665, \t output: -0.704, \t loss: 0.002\n",
      "i: 197, \t target: -0.896, \t output: -0.939, \t loss: 0.002\n",
      "i: 198, \t target: 1.270, \t output: 1.410, \t loss: 0.020\n",
      "i: 199, \t target: 0.382, \t output: 0.340, \t loss: 0.002\n",
      "i: 200, \t target: -0.787, \t output: -0.854, \t loss: 0.004\n",
      "i: 201, \t target: -0.766, \t output: -0.756, \t loss: 0.000\n",
      "i: 202, \t target: 0.267, \t output: 0.254, \t loss: 0.000\n",
      "i: 203, \t target: 1.900, \t output: 1.915, \t loss: 0.000\n",
      "i: 204, \t target: 0.582, \t output: 0.633, \t loss: 0.003\n",
      "i: 205, \t target: 1.972, \t output: 2.005, \t loss: 0.001\n",
      "i: 206, \t target: 2.105, \t output: 2.082, \t loss: 0.001\n",
      "i: 207, \t target: 2.138, \t output: 2.290, \t loss: 0.023\n",
      "i: 208, \t target: 1.307, \t output: 1.258, \t loss: 0.002\n",
      "i: 209, \t target: -1.039, \t output: -1.122, \t loss: 0.007\n",
      "i: 210, \t target: 0.537, \t output: 0.586, \t loss: 0.002\n",
      "i: 211, \t target: 1.739, \t output: 1.690, \t loss: 0.002\n",
      "i: 212, \t target: 1.944, \t output: 2.062, \t loss: 0.014\n",
      "i: 213, \t target: 0.967, \t output: 0.974, \t loss: 0.000\n",
      "i: 214, \t target: -0.985, \t output: -1.056, \t loss: 0.005\n",
      "i: 215, \t target: -0.620, \t output: -0.659, \t loss: 0.002\n",
      "i: 216, \t target: -0.510, \t output: -0.611, \t loss: 0.010\n",
      "i: 217, \t target: -0.837, \t output: -0.900, \t loss: 0.004\n",
      "i: 218, \t target: -0.253, \t output: -0.264, \t loss: 0.000\n",
      "i: 219, \t target: -0.766, \t output: -0.821, \t loss: 0.003\n",
      "i: 220, \t target: 0.697, \t output: 0.717, \t loss: 0.000\n",
      "i: 221, \t target: 1.167, \t output: 1.250, \t loss: 0.007\n",
      "i: 222, \t target: -0.863, \t output: -0.890, \t loss: 0.001\n",
      "i: 223, \t target: -0.745, \t output: -0.773, \t loss: 0.001\n",
      "i: 224, \t target: -0.565, \t output: -0.587, \t loss: 0.001\n",
      "i: 225, \t target: -0.944, \t output: -1.010, \t loss: 0.004\n",
      "i: 226, \t target: -0.836, \t output: -0.886, \t loss: 0.002\n",
      "i: 227, \t target: 0.958, \t output: 1.016, \t loss: 0.003\n",
      "i: 228, \t target: -0.598, \t output: -0.643, \t loss: 0.002\n",
      "i: 229, \t target: -0.767, \t output: -0.768, \t loss: 0.000\n",
      "i: 230, \t target: 1.990, \t output: 1.937, \t loss: 0.003\n",
      "i: 231, \t target: 1.917, \t output: 1.908, \t loss: 0.000\n",
      "i: 232, \t target: 0.485, \t output: 0.491, \t loss: 0.000\n",
      "i: 233, \t target: 1.439, \t output: 1.448, \t loss: 0.000\n",
      "i: 234, \t target: -0.158, \t output: -0.277, \t loss: 0.014\n",
      "i: 235, \t target: -0.768, \t output: -0.857, \t loss: 0.008\n",
      "i: 236, \t target: 0.054, \t output: 0.036, \t loss: 0.000\n",
      "i: 237, \t target: -0.753, \t output: -0.794, \t loss: 0.002\n",
      "i: 238, \t target: 1.574, \t output: 1.616, \t loss: 0.002\n",
      "i: 239, \t target: -0.609, \t output: -0.628, \t loss: 0.000\n",
      "i: 240, \t target: -0.704, \t output: -0.746, \t loss: 0.002\n",
      "i: 241, \t target: -0.464, \t output: -0.493, \t loss: 0.001\n",
      "i: 242, \t target: 2.565, \t output: 2.597, \t loss: 0.001\n",
      "i: 243, \t target: -0.462, \t output: -0.456, \t loss: 0.000\n",
      "i: 244, \t target: -0.785, \t output: -0.831, \t loss: 0.002\n",
      "i: 245, \t target: 0.638, \t output: 0.655, \t loss: 0.000\n",
      "i: 246, \t target: -0.572, \t output: -0.632, \t loss: 0.004\n",
      "i: 247, \t target: -0.660, \t output: -0.736, \t loss: 0.006\n",
      "i: 248, \t target: -0.613, \t output: -0.672, \t loss: 0.003\n",
      "i: 249, \t target: 2.289, \t output: 2.568, \t loss: 0.078\n",
      "i: 250, \t target: 2.233, \t output: 2.240, \t loss: 0.000\n",
      "i: 251, \t target: -0.560, \t output: -0.619, \t loss: 0.003\n",
      "i: 252, \t target: 0.334, \t output: 0.243, \t loss: 0.008\n",
      "i: 253, \t target: 1.645, \t output: 1.758, \t loss: 0.013\n",
      "i: 254, \t target: -0.676, \t output: -0.702, \t loss: 0.001\n",
      "i: 255, \t target: 0.813, \t output: 0.833, \t loss: 0.000\n",
      "i: 256, \t target: -0.393, \t output: -0.323, \t loss: 0.005\n",
      "i: 257, \t target: -0.961, \t output: -1.072, \t loss: 0.012\n",
      "i: 258, \t target: -0.367, \t output: -0.164, \t loss: 0.041\n",
      "i: 259, \t target: -0.284, \t output: -0.317, \t loss: 0.001\n",
      "i: 260, \t target: 1.908, \t output: 1.910, \t loss: 0.000\n",
      "i: 261, \t target: -0.558, \t output: -0.563, \t loss: 0.000\n",
      "i: 262, \t target: -0.185, \t output: -0.224, \t loss: 0.002\n",
      "i: 263, \t target: -0.745, \t output: -0.735, \t loss: 0.000\n",
      "i: 264, \t target: -0.773, \t output: -0.758, \t loss: 0.000\n",
      "i: 265, \t target: -0.529, \t output: -0.525, \t loss: 0.000\n",
      "i: 266, \t target: -0.540, \t output: -0.547, \t loss: 0.000\n",
      "i: 267, \t target: 2.472, \t output: 2.394, \t loss: 0.006\n",
      "i: 268, \t target: 0.837, \t output: 0.830, \t loss: 0.000\n",
      "i: 269, \t target: 0.468, \t output: 0.460, \t loss: 0.000\n",
      "i: 270, \t target: 2.099, \t output: 2.026, \t loss: 0.005\n",
      "i: 271, \t target: 1.886, \t output: 2.012, \t loss: 0.016\n",
      "i: 272, \t target: 0.007, \t output: -0.046, \t loss: 0.003\n",
      "i: 273, \t target: 3.542, \t output: 3.659, \t loss: 0.014\n",
      "i: 274, \t target: -0.118, \t output: -0.104, \t loss: 0.000\n",
      "i: 275, \t target: -0.893, \t output: -0.790, \t loss: 0.011\n",
      "i: 276, \t target: 2.366, \t output: 2.423, \t loss: 0.003\n",
      "i: 277, \t target: 0.626, \t output: 0.621, \t loss: 0.000\n",
      "i: 278, \t target: -0.292, \t output: -0.313, \t loss: 0.000\n",
      "i: 279, \t target: 1.810, \t output: 1.708, \t loss: 0.011\n",
      "i: 280, \t target: -0.366, \t output: -0.396, \t loss: 0.001\n",
      "i: 281, \t target: -0.503, \t output: -0.518, \t loss: 0.000\n",
      "i: 282, \t target: -0.770, \t output: -0.830, \t loss: 0.004\n",
      "i: 283, \t target: 0.921, \t output: 0.986, \t loss: 0.004\n",
      "i: 284, \t target: 1.899, \t output: 2.015, \t loss: 0.013\n",
      "i: 285, \t target: 1.933, \t output: 1.997, \t loss: 0.004\n",
      "i: 286, \t target: -0.408, \t output: -0.409, \t loss: 0.000\n",
      "i: 287, \t target: -0.778, \t output: -0.826, \t loss: 0.002\n",
      "i: 288, \t target: 1.599, \t output: 1.629, \t loss: 0.001\n",
      "i: 289, \t target: 0.098, \t output: 0.062, \t loss: 0.001\n",
      "i: 290, \t target: 0.355, \t output: 0.343, \t loss: 0.000\n",
      "i: 291, \t target: 0.870, \t output: 0.908, \t loss: 0.001\n",
      "i: 292, \t target: 1.699, \t output: 1.678, \t loss: 0.000\n",
      "i: 293, \t target: 2.148, \t output: 2.177, \t loss: 0.001\n",
      "i: 294, \t target: -0.274, \t output: -0.230, \t loss: 0.002\n",
      "i: 295, \t target: -0.551, \t output: -0.557, \t loss: 0.000\n",
      "i: 296, \t target: 2.091, \t output: 2.111, \t loss: 0.000\n",
      "i: 297, \t target: 1.947, \t output: 2.099, \t loss: 0.023\n",
      "i: 298, \t target: 0.091, \t output: 0.077, \t loss: 0.000\n",
      "i: 299, \t target: 0.334, \t output: 0.334, \t loss: 0.000\n",
      "i: 300, \t target: 1.417, \t output: 1.481, \t loss: 0.004\n",
      "i: 301, \t target: -0.360, \t output: -0.332, \t loss: 0.001\n",
      "i: 302, \t target: -0.729, \t output: -0.795, \t loss: 0.004\n",
      "i: 303, \t target: -0.989, \t output: -1.039, \t loss: 0.002\n",
      "i: 304, \t target: 0.641, \t output: 0.648, \t loss: 0.000\n",
      "i: 305, \t target: -0.886, \t output: -0.946, \t loss: 0.004\n",
      "i: 306, \t target: 1.690, \t output: 1.698, \t loss: 0.000\n",
      "i: 307, \t target: 0.664, \t output: 0.497, \t loss: 0.028\n",
      "i: 308, \t target: 0.391, \t output: 0.390, \t loss: 0.000\n",
      "i: 309, \t target: -0.003, \t output: 0.547, \t loss: 0.302\n",
      "i: 310, \t target: -0.782, \t output: -0.809, \t loss: 0.001\n",
      "i: 311, \t target: -0.804, \t output: -0.835, \t loss: 0.001\n",
      "i: 312, \t target: 4.100, \t output: 4.331, \t loss: 0.053\n",
      "i: 313, \t target: -0.762, \t output: -0.772, \t loss: 0.000\n",
      "i: 314, \t target: 0.050, \t output: -0.015, \t loss: 0.004\n",
      "i: 315, \t target: 2.459, \t output: 2.448, \t loss: 0.000\n",
      "i: 316, \t target: -0.881, \t output: -0.895, \t loss: 0.000\n",
      "i: 317, \t target: -0.657, \t output: -0.654, \t loss: 0.000\n",
      "i: 318, \t target: -0.515, \t output: -0.559, \t loss: 0.002\n",
      "i: 319, \t target: 0.157, \t output: 0.120, \t loss: 0.001\n",
      "i: 320, \t target: -0.629, \t output: -0.740, \t loss: 0.012\n",
      "i: 321, \t target: -1.024, \t output: -1.092, \t loss: 0.005\n",
      "i: 322, \t target: 1.818, \t output: 1.752, \t loss: 0.004\n",
      "i: 323, \t target: -0.685, \t output: -0.714, \t loss: 0.001\n",
      "i: 324, \t target: 4.579, \t output: 4.533, \t loss: 0.002\n",
      "i: 325, \t target: -0.364, \t output: -0.387, \t loss: 0.001\n",
      "i: 326, \t target: -0.820, \t output: -0.867, \t loss: 0.002\n",
      "i: 327, \t target: 1.533, \t output: 1.599, \t loss: 0.004\n",
      "i: 328, \t target: 1.631, \t output: 1.671, \t loss: 0.002\n",
      "i: 329, \t target: 0.382, \t output: 0.350, \t loss: 0.001\n",
      "i: 330, \t target: -0.767, \t output: -0.872, \t loss: 0.011\n",
      "i: 331, \t target: -0.380, \t output: -0.598, \t loss: 0.047\n",
      "i: 332, \t target: 4.830, \t output: 4.931, \t loss: 0.010\n",
      "i: 333, \t target: 4.359, \t output: 4.383, \t loss: 0.001\n",
      "i: 334, \t target: -0.484, \t output: -0.473, \t loss: 0.000\n",
      "i: 335, \t target: 0.549, \t output: 0.532, \t loss: 0.000\n",
      "i: 336, \t target: -1.011, \t output: -1.109, \t loss: 0.010\n",
      "i: 337, \t target: -0.563, \t output: -0.520, \t loss: 0.002\n",
      "i: 338, \t target: -0.711, \t output: -0.762, \t loss: 0.003\n",
      "i: 339, \t target: 0.271, \t output: 0.243, \t loss: 0.001\n",
      "i: 340, \t target: 0.811, \t output: 0.757, \t loss: 0.003\n",
      "i: 341, \t target: -0.721, \t output: -0.743, \t loss: 0.001\n",
      "i: 342, \t target: 3.051, \t output: 3.130, \t loss: 0.006\n",
      "i: 343, \t target: -0.428, \t output: -0.420, \t loss: 0.000\n",
      "i: 344, \t target: -0.804, \t output: -0.818, \t loss: 0.000\n",
      "i: 345, \t target: 0.923, \t output: 0.856, \t loss: 0.004\n",
      "i: 346, \t target: 1.172, \t output: 1.156, \t loss: 0.000\n",
      "i: 347, \t target: -0.777, \t output: -0.791, \t loss: 0.000\n",
      "i: 348, \t target: 0.070, \t output: 0.062, \t loss: 0.000\n",
      "i: 349, \t target: 3.335, \t output: 3.325, \t loss: 0.000\n",
      "i: 350, \t target: -0.534, \t output: -0.573, \t loss: 0.001\n",
      "i: 351, \t target: 1.433, \t output: 1.432, \t loss: 0.000\n",
      "i: 352, \t target: 0.358, \t output: 0.266, \t loss: 0.008\n",
      "i: 353, \t target: 1.328, \t output: 1.287, \t loss: 0.002\n",
      "i: 354, \t target: 0.439, \t output: 0.393, \t loss: 0.002\n",
      "i: 355, \t target: -0.599, \t output: -0.635, \t loss: 0.001\n",
      "i: 356, \t target: -1.011, \t output: -1.139, \t loss: 0.016\n",
      "i: 357, \t target: -0.951, \t output: -1.008, \t loss: 0.003\n",
      "i: 358, \t target: -0.461, \t output: -0.479, \t loss: 0.000\n",
      "i: 359, \t target: -0.736, \t output: -0.772, \t loss: 0.001\n",
      "i: 360, \t target: -0.345, \t output: -0.364, \t loss: 0.000\n",
      "i: 361, \t target: 2.789, \t output: 2.778, \t loss: 0.000\n",
      "i: 362, \t target: -0.671, \t output: -0.697, \t loss: 0.001\n",
      "i: 363, \t target: 1.781, \t output: 1.723, \t loss: 0.003\n",
      "i: 364, \t target: 1.065, \t output: 1.112, \t loss: 0.002\n",
      "i: 365, \t target: -0.823, \t output: -0.887, \t loss: 0.004\n",
      "i: 366, \t target: 1.567, \t output: 1.640, \t loss: 0.005\n",
      "i: 367, \t target: -0.707, \t output: -0.784, \t loss: 0.006\n",
      "i: 368, \t target: -0.177, \t output: -0.193, \t loss: 0.000\n",
      "i: 369, \t target: -0.008, \t output: 0.031, \t loss: 0.002\n",
      "i: 370, \t target: 3.317, \t output: 3.411, \t loss: 0.009\n",
      "i: 371, \t target: -0.548, \t output: -0.593, \t loss: 0.002\n",
      "i: 372, \t target: 0.327, \t output: 0.396, \t loss: 0.005\n",
      "i: 373, \t target: -0.429, \t output: -0.486, \t loss: 0.003\n",
      "i: 374, \t target: -0.531, \t output: -0.519, \t loss: 0.000\n",
      "i: 375, \t target: -0.708, \t output: -0.768, \t loss: 0.004\n",
      "i: 376, \t target: -0.823, \t output: -0.894, \t loss: 0.005\n",
      "i: 377, \t target: -0.487, \t output: -0.558, \t loss: 0.005\n",
      "i: 378, \t target: 1.685, \t output: 1.657, \t loss: 0.001\n",
      "i: 379, \t target: -0.768, \t output: -0.823, \t loss: 0.003\n",
      "i: 380, \t target: -0.158, \t output: -0.201, \t loss: 0.002\n",
      "i: 381, \t target: -0.146, \t output: -0.175, \t loss: 0.001\n",
      "i: 382, \t target: -0.859, \t output: -0.965, \t loss: 0.011\n",
      "i: 383, \t target: 1.293, \t output: 1.383, \t loss: 0.008\n",
      "i: 384, \t target: -0.430, \t output: -0.440, \t loss: 0.000\n",
      "i: 385, \t target: 0.753, \t output: 0.663, \t loss: 0.008\n",
      "i: 386, \t target: -0.346, \t output: -0.442, \t loss: 0.009\n",
      "i: 387, \t target: -0.666, \t output: -0.678, \t loss: 0.000\n",
      "i: 388, \t target: -0.911, \t output: -0.979, \t loss: 0.005\n",
      "i: 389, \t target: -0.659, \t output: -0.693, \t loss: 0.001\n",
      "i: 390, \t target: 4.133, \t output: 4.499, \t loss: 0.134\n",
      "i: 391, \t target: -0.563, \t output: -0.600, \t loss: 0.001\n",
      "i: 392, \t target: 0.203, \t output: 0.201, \t loss: 0.000\n",
      "i: 393, \t target: -0.722, \t output: -0.832, \t loss: 0.012\n",
      "i: 394, \t target: 0.997, \t output: 0.901, \t loss: 0.009\n",
      "i: 395, \t target: -0.726, \t output: -0.774, \t loss: 0.002\n",
      "i: 396, \t target: -0.711, \t output: -0.755, \t loss: 0.002\n",
      "i: 397, \t target: -1.141, \t output: -1.165, \t loss: 0.001\n",
      "i: 398, \t target: -0.130, \t output: -0.173, \t loss: 0.002\n",
      "i: 399, \t target: 2.623, \t output: 2.790, \t loss: 0.028\n",
      "i: 400, \t target: 1.571, \t output: 1.495, \t loss: 0.006\n",
      "i: 401, \t target: 0.093, \t output: 0.114, \t loss: 0.000\n",
      "i: 402, \t target: -0.907, \t output: -0.927, \t loss: 0.000\n",
      "i: 403, \t target: -0.797, \t output: -0.897, \t loss: 0.010\n",
      "i: 404, \t target: 1.193, \t output: 1.345, \t loss: 0.023\n",
      "i: 405, \t target: 1.939, \t output: 1.956, \t loss: 0.000\n",
      "i: 406, \t target: -0.721, \t output: -0.774, \t loss: 0.003\n",
      "i: 407, \t target: 2.248, \t output: 2.254, \t loss: 0.000\n",
      "i: 408, \t target: 1.950, \t output: 2.061, \t loss: 0.012\n",
      "i: 409, \t target: 1.952, \t output: 1.914, \t loss: 0.002\n",
      "i: 410, \t target: -0.749, \t output: -0.797, \t loss: 0.002\n",
      "i: 411, \t target: -0.823, \t output: -0.807, \t loss: 0.000\n",
      "i: 412, \t target: 2.004, \t output: 1.980, \t loss: 0.001\n",
      "i: 413, \t target: -0.762, \t output: -0.804, \t loss: 0.002\n",
      "i: 414, \t target: 0.874, \t output: 0.821, \t loss: 0.003\n",
      "i: 415, \t target: 2.320, \t output: 2.376, \t loss: 0.003\n",
      "i: 416, \t target: -0.705, \t output: -0.737, \t loss: 0.001\n",
      "i: 417, \t target: 0.460, \t output: 0.472, \t loss: 0.000\n",
      "i: 418, \t target: -1.043, \t output: -1.052, \t loss: 0.000\n",
      "i: 419, \t target: -0.808, \t output: -0.863, \t loss: 0.003\n",
      "i: 420, \t target: -0.994, \t output: -1.002, \t loss: 0.000\n",
      "i: 421, \t target: -0.821, \t output: -0.865, \t loss: 0.002\n",
      "i: 422, \t target: 0.344, \t output: 0.279, \t loss: 0.004\n",
      "i: 423, \t target: 1.913, \t output: 1.886, \t loss: 0.001\n",
      "i: 424, \t target: -0.575, \t output: -0.516, \t loss: 0.003\n",
      "i: 425, \t target: 2.430, \t output: 2.554, \t loss: 0.015\n",
      "i: 426, \t target: 1.528, \t output: 1.548, \t loss: 0.000\n",
      "i: 427, \t target: -0.546, \t output: -0.622, \t loss: 0.006\n",
      "i: 428, \t target: -0.820, \t output: -0.834, \t loss: 0.000\n",
      "i: 429, \t target: -0.559, \t output: -0.661, \t loss: 0.010\n",
      "i: 430, \t target: 1.793, \t output: 1.849, \t loss: 0.003\n",
      "i: 431, \t target: -0.692, \t output: -0.758, \t loss: 0.004\n",
      "i: 432, \t target: 1.299, \t output: 1.404, \t loss: 0.011\n",
      "i: 433, \t target: 4.166, \t output: 4.182, \t loss: 0.000\n",
      "i: 434, \t target: 1.061, \t output: 1.117, \t loss: 0.003\n",
      "i: 435, \t target: 0.441, \t output: 0.391, \t loss: 0.003\n",
      "i: 436, \t target: 2.445, \t output: 2.496, \t loss: 0.003\n",
      "i: 437, \t target: -0.769, \t output: -0.813, \t loss: 0.002\n",
      "i: 438, \t target: 3.917, \t output: 4.012, \t loss: 0.009\n",
      "i: 439, \t target: -0.828, \t output: -0.856, \t loss: 0.001\n",
      "i: 440, \t target: -0.458, \t output: -0.440, \t loss: 0.000\n",
      "i: 441, \t target: 0.436, \t output: 0.403, \t loss: 0.001\n",
      "i: 442, \t target: -0.821, \t output: -0.827, \t loss: 0.000\n",
      "i: 443, \t target: -0.483, \t output: -0.430, \t loss: 0.003\n",
      "i: 444, \t target: -0.557, \t output: -0.597, \t loss: 0.002\n",
      "i: 445, \t target: 2.099, \t output: 2.296, \t loss: 0.039\n",
      "i: 446, \t target: 2.037, \t output: 2.110, \t loss: 0.005\n",
      "i: 447, \t target: 1.230, \t output: 1.126, \t loss: 0.011\n",
      "i: 448, \t target: -0.566, \t output: -0.617, \t loss: 0.003\n",
      "i: 449, \t target: -0.690, \t output: -0.744, \t loss: 0.003\n",
      "i: 450, \t target: -0.212, \t output: -0.237, \t loss: 0.001\n",
      "i: 451, \t target: -0.689, \t output: -0.709, \t loss: 0.000\n",
      "i: 452, \t target: 1.568, \t output: 1.575, \t loss: 0.000\n",
      "i: 453, \t target: 0.894, \t output: 0.852, \t loss: 0.002\n",
      "i: 454, \t target: 1.836, \t output: 1.770, \t loss: 0.004\n",
      "i: 455, \t target: -0.363, \t output: -0.401, \t loss: 0.001\n",
      "i: 456, \t target: -0.713, \t output: -0.803, \t loss: 0.008\n",
      "i: 457, \t target: -0.422, \t output: -0.504, \t loss: 0.007\n",
      "i: 458, \t target: -0.872, \t output: -0.943, \t loss: 0.005\n",
      "i: 459, \t target: 0.908, \t output: 0.888, \t loss: 0.000\n",
      "i: 460, \t target: -0.473, \t output: -0.501, \t loss: 0.001\n",
      "i: 461, \t target: -0.383, \t output: -0.406, \t loss: 0.001\n",
      "i: 462, \t target: -0.749, \t output: -0.816, \t loss: 0.004\n",
      "i: 463, \t target: -0.748, \t output: -0.805, \t loss: 0.003\n",
      "i: 464, \t target: -0.181, \t output: -0.209, \t loss: 0.001\n",
      "i: 465, \t target: 2.419, \t output: 2.544, \t loss: 0.016\n",
      "i: 466, \t target: 1.323, \t output: 1.507, \t loss: 0.034\n",
      "i: 467, \t target: -0.863, \t output: -0.931, \t loss: 0.005\n",
      "i: 468, \t target: -0.423, \t output: -0.506, \t loss: 0.007\n",
      "i: 469, \t target: 1.696, \t output: 1.752, \t loss: 0.003\n",
      "i: 470, \t target: -0.761, \t output: -0.776, \t loss: 0.000\n",
      "i: 471, \t target: -0.741, \t output: -0.781, \t loss: 0.002\n",
      "i: 472, \t target: -0.660, \t output: -0.672, \t loss: 0.000\n",
      "i: 473, \t target: -0.560, \t output: -0.593, \t loss: 0.001\n",
      "i: 474, \t target: 1.869, \t output: 1.887, \t loss: 0.000\n",
      "i: 475, \t target: -0.501, \t output: -0.522, \t loss: 0.000\n",
      "i: 476, \t target: -0.860, \t output: -0.918, \t loss: 0.003\n",
      "i: 477, \t target: 0.688, \t output: 0.681, \t loss: 0.000\n",
      "i: 478, \t target: 0.427, \t output: 0.387, \t loss: 0.002\n",
      "i: 479, \t target: 1.952, \t output: 2.047, \t loss: 0.009\n",
      "i: 480, \t target: 1.263, \t output: 1.171, \t loss: 0.008\n",
      "i: 481, \t target: 1.151, \t output: 1.104, \t loss: 0.002\n",
      "i: 482, \t target: 0.739, \t output: 0.666, \t loss: 0.005\n",
      "i: 483, \t target: 1.602, \t output: 1.687, \t loss: 0.007\n",
      "i: 484, \t target: -0.564, \t output: -0.625, \t loss: 0.004\n",
      "i: 485, \t target: 1.859, \t output: 1.859, \t loss: 0.000\n",
      "i: 486, \t target: 0.067, \t output: 0.074, \t loss: 0.000\n",
      "i: 487, \t target: -0.779, \t output: -0.793, \t loss: 0.000\n",
      "i: 488, \t target: 0.848, \t output: 0.909, \t loss: 0.004\n",
      "i: 489, \t target: -0.584, \t output: -0.607, \t loss: 0.001\n",
      "i: 490, \t target: -0.643, \t output: -0.691, \t loss: 0.002\n",
      "i: 491, \t target: 0.600, \t output: 0.605, \t loss: 0.000\n",
      "i: 492, \t target: -0.782, \t output: -0.822, \t loss: 0.002\n",
      "i: 493, \t target: -0.693, \t output: -0.751, \t loss: 0.003\n",
      "i: 494, \t target: -1.039, \t output: -1.095, \t loss: 0.003\n",
      "i: 495, \t target: -0.807, \t output: -0.908, \t loss: 0.010\n",
      "i: 496, \t target: -0.413, \t output: -0.443, \t loss: 0.001\n",
      "i: 497, \t target: -0.492, \t output: -0.530, \t loss: 0.002\n",
      "i: 498, \t target: 1.897, \t output: 1.926, \t loss: 0.001\n",
      "i: 499, \t target: -0.642, \t output: -0.632, \t loss: 0.000\n",
      "i: 500, \t target: -0.546, \t output: -0.565, \t loss: 0.000\n",
      "i: 501, \t target: -0.398, \t output: -0.374, \t loss: 0.001\n",
      "i: 502, \t target: 2.165, \t output: 2.372, \t loss: 0.043\n",
      "i: 503, \t target: 1.420, \t output: 1.448, \t loss: 0.001\n",
      "i: 504, \t target: 1.124, \t output: 1.139, \t loss: 0.000\n",
      "i: 505, \t target: 1.531, \t output: 1.557, \t loss: 0.001\n",
      "i: 506, \t target: -0.160, \t output: -0.118, \t loss: 0.002\n",
      "i: 507, \t target: -0.326, \t output: -0.372, \t loss: 0.002\n",
      "i: 508, \t target: -0.851, \t output: -0.930, \t loss: 0.006\n",
      "i: 509, \t target: -0.772, \t output: -0.790, \t loss: 0.000\n",
      "i: 510, \t target: -0.686, \t output: -0.733, \t loss: 0.002\n",
      "i: 511, \t target: -0.603, \t output: -0.657, \t loss: 0.003\n",
      "i: 512, \t target: 2.656, \t output: 2.688, \t loss: 0.001\n",
      "i: 513, \t target: -0.485, \t output: -0.534, \t loss: 0.002\n",
      "i: 514, \t target: -0.665, \t output: -0.720, \t loss: 0.003\n",
      "i: 515, \t target: 1.082, \t output: 1.141, \t loss: 0.003\n",
      "i: 516, \t target: -0.104, \t output: -0.064, \t loss: 0.002\n",
      "i: 517, \t target: -0.349, \t output: -0.368, \t loss: 0.000\n",
      "i: 518, \t target: 0.058, \t output: -0.002, \t loss: 0.004\n",
      "i: 519, \t target: 1.926, \t output: 1.943, \t loss: 0.000\n",
      "i: 520, \t target: 3.905, \t output: 4.075, \t loss: 0.029\n",
      "i: 521, \t target: 0.495, \t output: 0.468, \t loss: 0.001\n",
      "i: 522, \t target: 1.802, \t output: 1.779, \t loss: 0.001\n",
      "i: 523, \t target: -0.482, \t output: -0.500, \t loss: 0.000\n",
      "i: 524, \t target: 1.454, \t output: 1.432, \t loss: 0.000\n",
      "i: 525, \t target: 1.266, \t output: 1.275, \t loss: 0.000\n",
      "i: 526, \t target: -0.301, \t output: -0.315, \t loss: 0.000\n",
      "i: 527, \t target: -0.764, \t output: -0.808, \t loss: 0.002\n",
      "i: 528, \t target: -0.388, \t output: -0.429, \t loss: 0.002\n",
      "i: 529, \t target: -0.460, \t output: -0.515, \t loss: 0.003\n",
      "i: 530, \t target: 2.906, \t output: 2.842, \t loss: 0.004\n",
      "i: 531, \t target: -0.777, \t output: -0.867, \t loss: 0.008\n",
      "i: 532, \t target: -0.402, \t output: -0.455, \t loss: 0.003\n",
      "i: 533, \t target: 1.453, \t output: 1.442, \t loss: 0.000\n",
      "i: 534, \t target: -0.873, \t output: -0.962, \t loss: 0.008\n",
      "i: 535, \t target: 1.236, \t output: 1.183, \t loss: 0.003\n",
      "i: 536, \t target: 0.588, \t output: 0.688, \t loss: 0.010\n",
      "i: 537, \t target: -0.916, \t output: -0.988, \t loss: 0.005\n",
      "i: 538, \t target: -0.564, \t output: -0.571, \t loss: 0.000\n",
      "i: 539, \t target: -0.626, \t output: -0.661, \t loss: 0.001\n",
      "i: 540, \t target: 1.644, \t output: 1.676, \t loss: 0.001\n",
      "i: 541, \t target: 0.004, \t output: -0.019, \t loss: 0.001\n",
      "i: 542, \t target: 1.998, \t output: 2.045, \t loss: 0.002\n",
      "i: 543, \t target: -0.556, \t output: -0.577, \t loss: 0.000\n",
      "i: 544, \t target: 4.487, \t output: 4.528, \t loss: 0.002\n",
      "i: 545, \t target: -0.680, \t output: -0.723, \t loss: 0.002\n",
      "i: 546, \t target: -0.430, \t output: -0.448, \t loss: 0.000\n",
      "i: 547, \t target: -0.755, \t output: -0.802, \t loss: 0.002\n",
      "i: 548, \t target: -0.945, \t output: -0.968, \t loss: 0.000\n",
      "i: 549, \t target: 2.177, \t output: 2.276, \t loss: 0.010\n",
      "i: 550, \t target: 1.240, \t output: 1.350, \t loss: 0.012\n",
      "i: 551, \t target: 1.714, \t output: 1.726, \t loss: 0.000\n",
      "i: 552, \t target: -0.655, \t output: -0.700, \t loss: 0.002\n",
      "i: 553, \t target: -0.443, \t output: -0.670, \t loss: 0.052\n",
      "i: 554, \t target: -0.893, \t output: -0.996, \t loss: 0.011\n",
      "i: 555, \t target: 2.329, \t output: 2.409, \t loss: 0.006\n",
      "i: 556, \t target: -0.768, \t output: -0.869, \t loss: 0.010\n",
      "i: 557, \t target: 0.848, \t output: 0.789, \t loss: 0.003\n",
      "i: 558, \t target: -0.710, \t output: -0.643, \t loss: 0.004\n",
      "i: 559, \t target: 1.908, \t output: 1.925, \t loss: 0.000\n",
      "i: 560, \t target: -0.711, \t output: -0.748, \t loss: 0.001\n",
      "i: 561, \t target: -0.476, \t output: -0.493, \t loss: 0.000\n",
      "i: 562, \t target: 1.829, \t output: 1.861, \t loss: 0.001\n",
      "i: 563, \t target: 3.420, \t output: 3.494, \t loss: 0.006\n",
      "i: 564, \t target: -0.951, \t output: -0.985, \t loss: 0.001\n",
      "i: 565, \t target: 4.020, \t output: 4.139, \t loss: 0.014\n",
      "i: 566, \t target: 1.979, \t output: 1.910, \t loss: 0.005\n",
      "i: 567, \t target: -0.511, \t output: -0.586, \t loss: 0.006\n",
      "i: 568, \t target: 0.909, \t output: 0.907, \t loss: 0.000\n",
      "i: 569, \t target: 3.037, \t output: 3.114, \t loss: 0.006\n",
      "i: 570, \t target: -0.482, \t output: -0.650, \t loss: 0.028\n",
      "i: 571, \t target: 0.854, \t output: 0.825, \t loss: 0.001\n",
      "i: 572, \t target: -0.297, \t output: -0.333, \t loss: 0.001\n",
      "i: 573, \t target: 1.377, \t output: 1.398, \t loss: 0.000\n",
      "i: 574, \t target: 0.291, \t output: 0.254, \t loss: 0.001\n",
      "i: 575, \t target: 2.081, \t output: 2.175, \t loss: 0.009\n",
      "i: 576, \t target: 0.375, \t output: 0.353, \t loss: 0.000\n",
      "i: 577, \t target: -0.616, \t output: -0.642, \t loss: 0.001\n",
      "i: 578, \t target: 1.660, \t output: 1.593, \t loss: 0.004\n",
      "i: 579, \t target: -0.809, \t output: -0.895, \t loss: 0.007\n",
      "i: 580, \t target: 1.894, \t output: 1.880, \t loss: 0.000\n",
      "i: 581, \t target: -1.042, \t output: -1.127, \t loss: 0.007\n",
      "i: 582, \t target: -0.467, \t output: -0.504, \t loss: 0.001\n",
      "i: 583, \t target: 1.596, \t output: 1.621, \t loss: 0.001\n",
      "i: 584, \t target: -0.655, \t output: -0.691, \t loss: 0.001\n",
      "i: 585, \t target: -0.716, \t output: -0.749, \t loss: 0.001\n",
      "i: 586, \t target: -0.206, \t output: -0.204, \t loss: 0.000\n",
      "i: 587, \t target: 1.929, \t output: 2.057, \t loss: 0.017\n",
      "i: 588, \t target: -0.448, \t output: -0.461, \t loss: 0.000\n",
      "i: 589, \t target: -0.269, \t output: -0.317, \t loss: 0.002\n",
      "i: 590, \t target: -0.789, \t output: -0.834, \t loss: 0.002\n",
      "i: 591, \t target: 2.143, \t output: 2.252, \t loss: 0.012\n",
      "i: 592, \t target: -0.862, \t output: -0.894, \t loss: 0.001\n",
      "i: 593, \t target: 0.260, \t output: 0.251, \t loss: 0.000\n",
      "i: 594, \t target: 1.255, \t output: 1.275, \t loss: 0.000\n",
      "i: 595, \t target: 3.095, \t output: 3.107, \t loss: 0.000\n",
      "i: 596, \t target: -0.174, \t output: -0.204, \t loss: 0.001\n",
      "i: 597, \t target: 0.040, \t output: -0.052, \t loss: 0.008\n",
      "i: 598, \t target: -0.392, \t output: -0.446, \t loss: 0.003\n",
      "i: 599, \t target: -0.285, \t output: -0.277, \t loss: 0.000\n",
      "i: 600, \t target: 0.464, \t output: 0.294, \t loss: 0.029\n",
      "i: 601, \t target: -0.547, \t output: -0.622, \t loss: 0.006\n",
      "i: 602, \t target: -0.559, \t output: -0.582, \t loss: 0.001\n",
      "i: 603, \t target: 1.558, \t output: 1.758, \t loss: 0.040\n",
      "i: 604, \t target: -0.446, \t output: -0.482, \t loss: 0.001\n",
      "i: 605, \t target: -0.737, \t output: -0.783, \t loss: 0.002\n",
      "i: 606, \t target: 1.951, \t output: 2.108, \t loss: 0.025\n",
      "i: 607, \t target: -0.510, \t output: -0.544, \t loss: 0.001\n",
      "i: 608, \t target: -0.786, \t output: -0.837, \t loss: 0.003\n",
      "i: 609, \t target: -0.596, \t output: -0.621, \t loss: 0.001\n",
      "i: 610, \t target: -0.323, \t output: -0.332, \t loss: 0.000\n",
      "i: 611, \t target: 1.845, \t output: 1.820, \t loss: 0.001\n",
      "i: 612, \t target: 2.912, \t output: 2.840, \t loss: 0.005\n",
      "i: 613, \t target: -0.396, \t output: -0.387, \t loss: 0.000\n",
      "i: 614, \t target: -0.718, \t output: -0.807, \t loss: 0.008\n",
      "i: 615, \t target: -0.913, \t output: -0.996, \t loss: 0.007\n",
      "i: 616, \t target: 1.881, \t output: 1.961, \t loss: 0.006\n",
      "i: 617, \t target: 2.202, \t output: 2.253, \t loss: 0.003\n",
      "i: 618, \t target: 1.843, \t output: 1.735, \t loss: 0.012\n",
      "i: 619, \t target: -0.612, \t output: -0.624, \t loss: 0.000\n",
      "i: 620, \t target: -0.727, \t output: -0.789, \t loss: 0.004\n",
      "i: 621, \t target: -0.548, \t output: -0.595, \t loss: 0.002\n",
      "i: 622, \t target: 1.414, \t output: 1.366, \t loss: 0.002\n",
      "i: 623, \t target: -0.618, \t output: -0.682, \t loss: 0.004\n",
      "i: 624, \t target: 1.303, \t output: 1.340, \t loss: 0.001\n",
      "i: 625, \t target: -0.454, \t output: -0.461, \t loss: 0.000\n",
      "i: 626, \t target: 0.287, \t output: 0.243, \t loss: 0.002\n",
      "i: 627, \t target: 0.180, \t output: 0.144, \t loss: 0.001\n",
      "i: 628, \t target: 1.040, \t output: 1.031, \t loss: 0.000\n",
      "i: 629, \t target: 4.666, \t output: 4.983, \t loss: 0.101\n",
      "i: 630, \t target: -0.457, \t output: -0.513, \t loss: 0.003\n",
      "i: 631, \t target: -0.558, \t output: -0.534, \t loss: 0.001\n",
      "i: 632, \t target: -0.808, \t output: -0.841, \t loss: 0.001\n",
      "i: 633, \t target: -0.465, \t output: -0.411, \t loss: 0.003\n",
      "i: 634, \t target: -0.759, \t output: -0.811, \t loss: 0.003\n",
      "i: 635, \t target: 1.938, \t output: 1.902, \t loss: 0.001\n",
      "i: 636, \t target: 1.022, \t output: 0.989, \t loss: 0.001\n",
      "i: 637, \t target: -0.660, \t output: -0.739, \t loss: 0.006\n",
      "i: 638, \t target: -0.687, \t output: -0.732, \t loss: 0.002\n",
      "i: 639, \t target: 0.063, \t output: 0.034, \t loss: 0.001\n",
      "i: 640, \t target: -0.351, \t output: -0.437, \t loss: 0.007\n",
      "i: 641, \t target: -0.774, \t output: -0.818, \t loss: 0.002\n",
      "i: 642, \t target: -0.723, \t output: -0.776, \t loss: 0.003\n",
      "i: 643, \t target: 1.694, \t output: 1.844, \t loss: 0.023\n",
      "i: 644, \t target: 0.372, \t output: 0.339, \t loss: 0.001\n",
      "i: 645, \t target: -0.833, \t output: -0.867, \t loss: 0.001\n",
      "i: 646, \t target: -0.168, \t output: -0.206, \t loss: 0.001\n",
      "i: 647, \t target: -0.590, \t output: -0.607, \t loss: 0.000\n",
      "i: 648, \t target: -0.727, \t output: -0.794, \t loss: 0.005\n",
      "i: 649, \t target: -0.696, \t output: -0.774, \t loss: 0.006\n",
      "i: 650, \t target: -0.811, \t output: -0.912, \t loss: 0.010\n",
      "i: 651, \t target: -0.428, \t output: -0.440, \t loss: 0.000\n",
      "i: 652, \t target: 1.918, \t output: 1.931, \t loss: 0.000\n",
      "i: 653, \t target: 2.002, \t output: 2.002, \t loss: 0.000\n",
      "i: 654, \t target: -0.526, \t output: -0.567, \t loss: 0.002\n",
      "i: 655, \t target: 1.907, \t output: 1.883, \t loss: 0.001\n",
      "i: 656, \t target: -0.393, \t output: -0.410, \t loss: 0.000\n",
      "i: 657, \t target: -0.320, \t output: -0.402, \t loss: 0.007\n",
      "i: 658, \t target: -0.450, \t output: -0.498, \t loss: 0.002\n",
      "i: 659, \t target: -0.652, \t output: -0.677, \t loss: 0.001\n",
      "i: 660, \t target: -0.759, \t output: -0.783, \t loss: 0.001\n",
      "i: 661, \t target: 0.652, \t output: 0.544, \t loss: 0.012\n",
      "i: 662, \t target: 4.538, \t output: 4.775, \t loss: 0.056\n",
      "i: 663, \t target: 0.142, \t output: 0.116, \t loss: 0.001\n",
      "i: 664, \t target: 1.756, \t output: 1.670, \t loss: 0.007\n",
      "i: 665, \t target: 1.847, \t output: 1.816, \t loss: 0.001\n",
      "i: 666, \t target: -0.813, \t output: -0.888, \t loss: 0.006\n",
      "i: 667, \t target: -0.772, \t output: -0.859, \t loss: 0.007\n",
      "i: 668, \t target: -0.673, \t output: -0.699, \t loss: 0.001\n",
      "i: 669, \t target: -0.402, \t output: -0.461, \t loss: 0.003\n",
      "i: 670, \t target: -0.659, \t output: -0.728, \t loss: 0.005\n",
      "i: 671, \t target: -0.755, \t output: -0.818, \t loss: 0.004\n",
      "i: 672, \t target: 1.649, \t output: 1.639, \t loss: 0.000\n",
      "i: 673, \t target: -0.653, \t output: -0.698, \t loss: 0.002\n",
      "i: 674, \t target: -0.789, \t output: -0.848, \t loss: 0.004\n",
      "i: 675, \t target: -0.687, \t output: -0.755, \t loss: 0.005\n",
      "i: 676, \t target: -0.362, \t output: -0.407, \t loss: 0.002\n",
      "i: 677, \t target: -0.366, \t output: -0.397, \t loss: 0.001\n",
      "i: 678, \t target: -0.701, \t output: -0.768, \t loss: 0.005\n",
      "i: 679, \t target: -0.935, \t output: -0.887, \t loss: 0.002\n",
      "i: 680, \t target: -0.957, \t output: -1.008, \t loss: 0.003\n",
      "i: 681, \t target: -0.137, \t output: -0.109, \t loss: 0.001\n",
      "i: 682, \t target: 1.367, \t output: 1.405, \t loss: 0.001\n",
      "i: 683, \t target: 2.016, \t output: 2.019, \t loss: 0.000\n",
      "i: 684, \t target: 1.735, \t output: 1.703, \t loss: 0.001\n",
      "i: 685, \t target: 1.497, \t output: 1.527, \t loss: 0.001\n",
      "i: 686, \t target: 0.137, \t output: 0.085, \t loss: 0.003\n",
      "i: 687, \t target: -0.654, \t output: -0.702, \t loss: 0.002\n",
      "i: 688, \t target: 1.882, \t output: 1.838, \t loss: 0.002\n",
      "i: 689, \t target: 1.402, \t output: 1.432, \t loss: 0.001\n",
      "i: 690, \t target: 0.721, \t output: 0.778, \t loss: 0.003\n",
      "i: 691, \t target: -0.767, \t output: -0.783, \t loss: 0.000\n",
      "i: 692, \t target: 1.881, \t output: 1.931, \t loss: 0.002\n",
      "i: 693, \t target: -0.799, \t output: -0.778, \t loss: 0.000\n",
      "i: 694, \t target: -0.497, \t output: -0.560, \t loss: 0.004\n",
      "i: 695, \t target: 0.387, \t output: 0.344, \t loss: 0.002\n",
      "i: 696, \t target: 1.117, \t output: 1.183, \t loss: 0.004\n",
      "i: 697, \t target: -0.530, \t output: -0.626, \t loss: 0.009\n",
      "i: 698, \t target: -0.741, \t output: -0.765, \t loss: 0.001\n",
      "i: 699, \t target: -0.316, \t output: -0.372, \t loss: 0.003\n",
      "i: 700, \t target: -0.679, \t output: -0.748, \t loss: 0.005\n",
      "i: 701, \t target: -0.768, \t output: -0.865, \t loss: 0.009\n",
      "i: 702, \t target: 0.272, \t output: 0.227, \t loss: 0.002\n",
      "i: 703, \t target: -0.766, \t output: -0.856, \t loss: 0.008\n",
      "i: 704, \t target: 1.059, \t output: 1.171, \t loss: 0.012\n",
      "i: 705, \t target: -0.615, \t output: -0.674, \t loss: 0.004\n",
      "i: 706, \t target: 1.127, \t output: 1.146, \t loss: 0.000\n",
      "i: 707, \t target: 1.949, \t output: 2.059, \t loss: 0.012\n",
      "i: 708, \t target: -0.811, \t output: -0.860, \t loss: 0.002\n",
      "i: 709, \t target: 1.449, \t output: 1.435, \t loss: 0.000\n",
      "i: 710, \t target: -0.597, \t output: -0.639, \t loss: 0.002\n",
      "i: 711, \t target: -0.843, \t output: -0.890, \t loss: 0.002\n",
      "i: 712, \t target: -1.098, \t output: -1.122, \t loss: 0.001\n",
      "i: 713, \t target: -0.408, \t output: -0.458, \t loss: 0.003\n",
      "i: 714, \t target: -0.797, \t output: -0.839, \t loss: 0.002\n",
      "i: 715, \t target: -0.420, \t output: -0.439, \t loss: 0.000\n",
      "i: 716, \t target: -0.701, \t output: -0.759, \t loss: 0.003\n",
      "i: 717, \t target: 1.967, \t output: 2.031, \t loss: 0.004\n",
      "i: 718, \t target: 0.206, \t output: 0.171, \t loss: 0.001\n",
      "i: 719, \t target: -0.311, \t output: -0.363, \t loss: 0.003\n",
      "i: 720, \t target: 2.073, \t output: 2.057, \t loss: 0.000\n",
      "i: 721, \t target: 1.485, \t output: 1.491, \t loss: 0.000\n",
      "i: 722, \t target: 0.263, \t output: 0.229, \t loss: 0.001\n",
      "i: 723, \t target: 1.272, \t output: 1.247, \t loss: 0.001\n",
      "i: 724, \t target: 1.916, \t output: 1.919, \t loss: 0.000\n",
      "i: 725, \t target: -0.403, \t output: -0.471, \t loss: 0.005\n",
      "i: 726, \t target: 1.934, \t output: 1.934, \t loss: 0.000\n",
      "i: 727, \t target: -0.453, \t output: -0.454, \t loss: 0.000\n",
      "i: 728, \t target: -0.822, \t output: -0.872, \t loss: 0.003\n",
      "i: 729, \t target: 1.915, \t output: 1.940, \t loss: 0.001\n",
      "i: 730, \t target: 1.778, \t output: 1.749, \t loss: 0.001\n",
      "i: 731, \t target: 1.516, \t output: 1.542, \t loss: 0.001\n",
      "i: 732, \t target: -0.764, \t output: -0.793, \t loss: 0.001\n",
      "i: 733, \t target: 0.038, \t output: 0.008, \t loss: 0.001\n",
      "i: 734, \t target: 1.839, \t output: 1.748, \t loss: 0.008\n",
      "i: 735, \t target: -0.770, \t output: -0.799, \t loss: 0.001\n",
      "i: 736, \t target: 1.002, \t output: 0.956, \t loss: 0.002\n",
      "i: 737, \t target: -0.606, \t output: -0.664, \t loss: 0.003\n",
      "i: 738, \t target: 1.231, \t output: 1.311, \t loss: 0.006\n",
      "i: 739, \t target: -0.720, \t output: -0.776, \t loss: 0.003\n",
      "i: 740, \t target: -0.840, \t output: -0.887, \t loss: 0.002\n",
      "i: 741, \t target: -0.423, \t output: -0.433, \t loss: 0.000\n",
      "i: 742, \t target: 0.437, \t output: 0.471, \t loss: 0.001\n",
      "i: 743, \t target: 2.061, \t output: 2.060, \t loss: 0.000\n",
      "i: 744, \t target: 0.941, \t output: 0.876, \t loss: 0.004\n",
      "i: 745, \t target: 0.872, \t output: 0.892, \t loss: 0.000\n",
      "i: 746, \t target: -1.005, \t output: -0.987, \t loss: 0.000\n",
      "i: 747, \t target: -0.762, \t output: -0.772, \t loss: 0.000\n",
      "i: 748, \t target: -0.726, \t output: -0.722, \t loss: 0.000\n",
      "i: 749, \t target: -0.990, \t output: -1.031, \t loss: 0.002\n",
      "i: 750, \t target: -0.304, \t output: -0.315, \t loss: 0.000\n",
      "i: 751, \t target: 2.436, \t output: 2.504, \t loss: 0.005\n",
      "i: 752, \t target: 1.381, \t output: 1.339, \t loss: 0.002\n",
      "i: 753, \t target: -0.924, \t output: -0.993, \t loss: 0.005\n",
      "i: 754, \t target: 1.665, \t output: 1.677, \t loss: 0.000\n",
      "i: 755, \t target: -0.651, \t output: -0.727, \t loss: 0.006\n",
      "i: 756, \t target: 0.113, \t output: 0.138, \t loss: 0.001\n",
      "i: 757, \t target: -0.845, \t output: -0.884, \t loss: 0.002\n",
      "i: 758, \t target: -0.589, \t output: -0.582, \t loss: 0.000\n",
      "i: 759, \t target: -0.820, \t output: -0.897, \t loss: 0.006\n",
      "i: 760, \t target: 1.190, \t output: 1.222, \t loss: 0.001\n",
      "i: 761, \t target: 1.978, \t output: 1.990, \t loss: 0.000\n",
      "i: 762, \t target: -0.739, \t output: -0.845, \t loss: 0.011\n",
      "i: 763, \t target: -0.446, \t output: -0.339, \t loss: 0.011\n",
      "i: 764, \t target: -0.766, \t output: -0.757, \t loss: 0.000\n",
      "i: 765, \t target: -0.016, \t output: -0.014, \t loss: 0.000\n",
      "i: 766, \t target: -0.643, \t output: -0.692, \t loss: 0.002\n",
      "i: 767, \t target: 0.730, \t output: 0.717, \t loss: 0.000\n",
      "i: 768, \t target: -0.544, \t output: -0.576, \t loss: 0.001\n",
      "i: 769, \t target: 0.287, \t output: 0.230, \t loss: 0.003\n",
      "i: 770, \t target: 2.186, \t output: 2.448, \t loss: 0.069\n",
      "i: 771, \t target: -0.650, \t output: -0.705, \t loss: 0.003\n",
      "i: 772, \t target: -0.576, \t output: -0.628, \t loss: 0.003\n",
      "i: 773, \t target: 0.959, \t output: 0.957, \t loss: 0.000\n",
      "i: 774, \t target: 1.782, \t output: 1.891, \t loss: 0.012\n",
      "i: 775, \t target: -0.772, \t output: -0.859, \t loss: 0.007\n",
      "i: 776, \t target: -0.856, \t output: -0.894, \t loss: 0.001\n",
      "i: 777, \t target: 0.083, \t output: 0.044, \t loss: 0.002\n",
      "i: 778, \t target: -0.701, \t output: -0.726, \t loss: 0.001\n",
      "i: 779, \t target: -0.177, \t output: -0.160, \t loss: 0.000\n",
      "i: 780, \t target: -0.934, \t output: -0.858, \t loss: 0.006\n",
      "i: 781, \t target: -0.775, \t output: -0.810, \t loss: 0.001\n",
      "i: 782, \t target: 1.457, \t output: 1.445, \t loss: 0.000\n",
      "i: 783, \t target: -0.487, \t output: -0.520, \t loss: 0.001\n",
      "i: 784, \t target: -0.620, \t output: -0.676, \t loss: 0.003\n",
      "i: 785, \t target: 0.024, \t output: -0.039, \t loss: 0.004\n",
      "i: 786, \t target: -0.374, \t output: -0.340, \t loss: 0.001\n",
      "i: 787, \t target: 1.622, \t output: 1.640, \t loss: 0.000\n",
      "i: 788, \t target: 2.458, \t output: 2.280, \t loss: 0.032\n",
      "i: 789, \t target: -0.353, \t output: -0.355, \t loss: 0.000\n",
      "i: 790, \t target: -0.715, \t output: -0.804, \t loss: 0.008\n",
      "i: 791, \t target: 1.757, \t output: 1.743, \t loss: 0.000\n",
      "i: 792, \t target: 2.181, \t output: 2.266, \t loss: 0.007\n",
      "i: 793, \t target: -0.694, \t output: -0.717, \t loss: 0.001\n",
      "i: 794, \t target: -0.178, \t output: -0.226, \t loss: 0.002\n",
      "i: 795, \t target: 1.301, \t output: 1.395, \t loss: 0.009\n",
      "i: 796, \t target: -0.699, \t output: -0.774, \t loss: 0.006\n",
      "i: 797, \t target: 0.974, \t output: 0.954, \t loss: 0.000\n",
      "i: 798, \t target: -0.654, \t output: -0.683, \t loss: 0.001\n",
      "i: 799, \t target: -0.744, \t output: -0.786, \t loss: 0.002\n",
      "i: 800, \t target: -0.671, \t output: -0.701, \t loss: 0.001\n",
      "i: 801, \t target: 1.426, \t output: 1.520, \t loss: 0.009\n",
      "i: 802, \t target: -0.709, \t output: -0.768, \t loss: 0.004\n",
      "i: 803, \t target: 1.349, \t output: 1.277, \t loss: 0.005\n",
      "i: 804, \t target: 1.725, \t output: 1.734, \t loss: 0.000\n",
      "i: 805, \t target: 2.148, \t output: 2.341, \t loss: 0.037\n",
      "i: 806, \t target: 0.056, \t output: 0.093, \t loss: 0.001\n",
      "i: 807, \t target: -0.811, \t output: -0.876, \t loss: 0.004\n",
      "i: 808, \t target: 1.885, \t output: 1.873, \t loss: 0.000\n",
      "i: 809, \t target: 0.735, \t output: 0.641, \t loss: 0.009\n",
      "i: 810, \t target: 3.111, \t output: 3.176, \t loss: 0.004\n",
      "i: 811, \t target: -0.840, \t output: -0.893, \t loss: 0.003\n",
      "i: 812, \t target: -1.043, \t output: -1.106, \t loss: 0.004\n",
      "i: 813, \t target: -0.597, \t output: -0.632, \t loss: 0.001\n",
      "i: 814, \t target: -0.931, \t output: -0.995, \t loss: 0.004\n",
      "i: 815, \t target: -0.737, \t output: -0.779, \t loss: 0.002\n",
      "i: 816, \t target: -0.842, \t output: -0.896, \t loss: 0.003\n",
      "i: 817, \t target: -0.583, \t output: -0.607, \t loss: 0.001\n",
      "i: 818, \t target: -0.995, \t output: -1.005, \t loss: 0.000\n",
      "i: 819, \t target: -0.533, \t output: -0.603, \t loss: 0.005\n",
      "i: 820, \t target: 1.934, \t output: 2.007, \t loss: 0.005\n",
      "i: 821, \t target: 2.153, \t output: 2.145, \t loss: 0.000\n",
      "i: 822, \t target: -0.488, \t output: -0.568, \t loss: 0.006\n",
      "i: 823, \t target: -0.575, \t output: -0.569, \t loss: 0.000\n",
      "i: 824, \t target: -0.870, \t output: -0.910, \t loss: 0.002\n",
      "i: 825, \t target: 3.287, \t output: 3.411, \t loss: 0.015\n",
      "i: 826, \t target: -0.586, \t output: -0.623, \t loss: 0.001\n",
      "i: 827, \t target: -0.813, \t output: -0.898, \t loss: 0.007\n",
      "i: 828, \t target: 0.668, \t output: 0.615, \t loss: 0.003\n",
      "i: 829, \t target: 0.465, \t output: 0.427, \t loss: 0.001\n",
      "i: 830, \t target: 6.005, \t output: 6.261, \t loss: 0.065\n",
      "i: 831, \t target: -0.237, \t output: -0.285, \t loss: 0.002\n",
      "i: 832, \t target: -0.847, \t output: -0.913, \t loss: 0.004\n",
      "i: 833, \t target: -0.109, \t output: -0.170, \t loss: 0.004\n",
      "i: 834, \t target: 0.113, \t output: 0.144, \t loss: 0.001\n",
      "i: 835, \t target: -0.155, \t output: -0.221, \t loss: 0.004\n",
      "i: 836, \t target: 2.280, \t output: 2.360, \t loss: 0.006\n",
      "i: 837, \t target: -0.902, \t output: -0.982, \t loss: 0.006\n",
      "i: 838, \t target: -0.364, \t output: -0.358, \t loss: 0.000\n",
      "i: 839, \t target: 2.224, \t output: 2.355, \t loss: 0.017\n",
      "i: 840, \t target: 1.184, \t output: 1.175, \t loss: 0.000\n",
      "i: 841, \t target: -0.901, \t output: -0.913, \t loss: 0.000\n",
      "i: 842, \t target: 1.789, \t output: 1.881, \t loss: 0.009\n",
      "i: 843, \t target: 2.233, \t output: 2.142, \t loss: 0.008\n",
      "i: 844, \t target: 1.400, \t output: 1.432, \t loss: 0.001\n",
      "i: 845, \t target: -0.836, \t output: -0.882, \t loss: 0.002\n",
      "i: 846, \t target: -0.480, \t output: -0.567, \t loss: 0.008\n",
      "i: 847, \t target: 1.454, \t output: 1.532, \t loss: 0.006\n",
      "i: 848, \t target: -0.611, \t output: -0.712, \t loss: 0.010\n",
      "i: 849, \t target: 1.975, \t output: 2.000, \t loss: 0.001\n",
      "i: 850, \t target: 1.147, \t output: 1.125, \t loss: 0.000\n",
      "i: 851, \t target: -0.532, \t output: -0.570, \t loss: 0.001\n",
      "i: 852, \t target: 1.932, \t output: 1.940, \t loss: 0.000\n",
      "i: 853, \t target: -0.647, \t output: -0.702, \t loss: 0.003\n",
      "i: 854, \t target: 1.375, \t output: 1.434, \t loss: 0.003\n",
      "i: 855, \t target: 2.293, \t output: 2.321, \t loss: 0.001\n",
      "i: 856, \t target: -0.585, \t output: -0.675, \t loss: 0.008\n",
      "i: 857, \t target: 0.478, \t output: 0.473, \t loss: 0.000\n",
      "i: 858, \t target: 3.940, \t output: 4.115, \t loss: 0.031\n",
      "i: 859, \t target: -0.388, \t output: -0.293, \t loss: 0.009\n",
      "i: 860, \t target: 1.606, \t output: 1.740, \t loss: 0.018\n",
      "i: 861, \t target: -0.567, \t output: -0.563, \t loss: 0.000\n",
      "i: 862, \t target: 3.059, \t output: 3.336, \t loss: 0.077\n",
      "i: 863, \t target: 2.553, \t output: 2.562, \t loss: 0.000\n",
      "i: 864, \t target: -0.545, \t output: -0.529, \t loss: 0.000\n",
      "i: 865, \t target: -0.867, \t output: -0.968, \t loss: 0.010\n",
      "i: 866, \t target: 1.469, \t output: 1.550, \t loss: 0.007\n",
      "i: 867, \t target: -0.270, \t output: -0.318, \t loss: 0.002\n",
      "i: 868, \t target: -0.445, \t output: -0.441, \t loss: 0.000\n",
      "i: 869, \t target: -1.132, \t output: -1.156, \t loss: 0.001\n",
      "i: 870, \t target: 1.742, \t output: 1.799, \t loss: 0.003\n",
      "i: 871, \t target: -0.589, \t output: -0.675, \t loss: 0.007\n",
      "i: 872, \t target: 1.358, \t output: 1.455, \t loss: 0.009\n",
      "i: 873, \t target: 0.975, \t output: 1.001, \t loss: 0.001\n",
      "i: 874, \t target: -0.559, \t output: -0.578, \t loss: 0.000\n",
      "i: 875, \t target: -0.725, \t output: -0.774, \t loss: 0.002\n",
      "i: 876, \t target: 0.158, \t output: 0.143, \t loss: 0.000\n",
      "i: 877, \t target: 2.166, \t output: 2.128, \t loss: 0.001\n",
      "i: 878, \t target: -0.763, \t output: -0.776, \t loss: 0.000\n",
      "i: 879, \t target: 2.043, \t output: 2.114, \t loss: 0.005\n",
      "i: 880, \t target: -0.232, \t output: -0.186, \t loss: 0.002\n",
      "i: 881, \t target: -0.555, \t output: -0.573, \t loss: 0.000\n",
      "i: 882, \t target: 2.473, \t output: 2.554, \t loss: 0.007\n",
      "i: 883, \t target: -0.816, \t output: -0.866, \t loss: 0.002\n",
      "i: 884, \t target: 1.703, \t output: 1.725, \t loss: 0.000\n",
      "i: 885, \t target: 2.156, \t output: 2.121, \t loss: 0.001\n",
      "i: 886, \t target: -0.778, \t output: -0.854, \t loss: 0.006\n",
      "i: 887, \t target: -0.712, \t output: -0.760, \t loss: 0.002\n",
      "i: 888, \t target: -0.717, \t output: -0.775, \t loss: 0.003\n",
      "i: 889, \t target: -0.534, \t output: -0.566, \t loss: 0.001\n",
      "i: 890, \t target: 0.272, \t output: 0.965, \t loss: 0.480\n",
      "i: 891, \t target: 0.217, \t output: 0.201, \t loss: 0.000\n",
      "i: 892, \t target: 3.678, \t output: 3.799, \t loss: 0.015\n",
      "i: 893, \t target: 1.355, \t output: 1.432, \t loss: 0.006\n",
      "i: 894, \t target: 1.919, \t output: 1.880, \t loss: 0.002\n",
      "i: 895, \t target: -0.674, \t output: -0.724, \t loss: 0.003\n",
      "i: 896, \t target: 1.832, \t output: 1.876, \t loss: 0.002\n",
      "i: 897, \t target: -0.688, \t output: -0.751, \t loss: 0.004\n",
      "i: 898, \t target: 0.995, \t output: 0.972, \t loss: 0.001\n",
      "i: 899, \t target: -0.683, \t output: -0.712, \t loss: 0.001\n",
      "i: 900, \t target: 0.730, \t output: 0.717, \t loss: 0.000\n",
      "i: 901, \t target: -0.761, \t output: -0.822, \t loss: 0.004\n",
      "i: 902, \t target: 0.534, \t output: 0.477, \t loss: 0.003\n",
      "i: 903, \t target: -0.711, \t output: -0.792, \t loss: 0.007\n",
      "i: 904, \t target: -0.799, \t output: -0.837, \t loss: 0.001\n",
      "i: 905, \t target: -0.510, \t output: -0.586, \t loss: 0.006\n",
      "i: 906, \t target: 0.408, \t output: 0.406, \t loss: 0.000\n",
      "i: 907, \t target: -0.034, \t output: -0.047, \t loss: 0.000\n",
      "i: 908, \t target: -0.909, \t output: -1.018, \t loss: 0.012\n",
      "i: 909, \t target: 1.434, \t output: 1.488, \t loss: 0.003\n",
      "i: 910, \t target: 2.233, \t output: 2.314, \t loss: 0.007\n",
      "i: 911, \t target: 2.268, \t output: 2.403, \t loss: 0.018\n",
      "i: 912, \t target: -0.640, \t output: -0.660, \t loss: 0.000\n",
      "i: 913, \t target: 1.101, \t output: 1.119, \t loss: 0.000\n",
      "i: 914, \t target: -0.390, \t output: -0.419, \t loss: 0.001\n",
      "i: 915, \t target: -0.552, \t output: -0.518, \t loss: 0.001\n",
      "i: 916, \t target: -0.569, \t output: -0.624, \t loss: 0.003\n",
      "i: 917, \t target: 0.900, \t output: 0.912, \t loss: 0.000\n",
      "i: 918, \t target: -0.173, \t output: -0.182, \t loss: 0.000\n",
      "i: 919, \t target: 0.441, \t output: 0.417, \t loss: 0.001\n",
      "i: 920, \t target: 2.033, \t output: 2.071, \t loss: 0.001\n",
      "i: 921, \t target: 1.062, \t output: 1.012, \t loss: 0.003\n",
      "i: 922, \t target: 0.060, \t output: 0.085, \t loss: 0.001\n",
      "i: 923, \t target: 2.050, \t output: 1.990, \t loss: 0.004\n",
      "i: 924, \t target: -0.793, \t output: -0.851, \t loss: 0.003\n",
      "i: 925, \t target: 1.332, \t output: 1.183, \t loss: 0.022\n",
      "i: 926, \t target: 0.175, \t output: 0.119, \t loss: 0.003\n",
      "i: 927, \t target: 0.216, \t output: 0.211, \t loss: 0.000\n",
      "i: 928, \t target: 0.513, \t output: 0.526, \t loss: 0.000\n",
      "i: 929, \t target: 0.224, \t output: 0.253, \t loss: 0.001\n",
      "i: 930, \t target: -0.699, \t output: -0.741, \t loss: 0.002\n",
      "i: 931, \t target: 2.317, \t output: 2.379, \t loss: 0.004\n",
      "i: 932, \t target: 1.805, \t output: 1.780, \t loss: 0.001\n",
      "i: 933, \t target: -0.767, \t output: -0.808, \t loss: 0.002\n",
      "i: 934, \t target: -0.551, \t output: -0.534, \t loss: 0.000\n",
      "i: 935, \t target: -0.661, \t output: -0.738, \t loss: 0.006\n",
      "i: 936, \t target: 2.152, \t output: 2.189, \t loss: 0.001\n",
      "i: 937, \t target: 2.170, \t output: 2.257, \t loss: 0.008\n",
      "i: 938, \t target: -0.939, \t output: -0.994, \t loss: 0.003\n",
      "i: 939, \t target: -0.808, \t output: -0.845, \t loss: 0.001\n",
      "i: 940, \t target: -0.504, \t output: -0.494, \t loss: 0.000\n",
      "i: 941, \t target: 2.073, \t output: 2.115, \t loss: 0.002\n",
      "i: 942, \t target: -0.765, \t output: -0.829, \t loss: 0.004\n",
      "i: 943, \t target: 1.924, \t output: 2.040, \t loss: 0.013\n",
      "i: 944, \t target: -0.766, \t output: -0.804, \t loss: 0.001\n",
      "i: 945, \t target: -0.517, \t output: -0.593, \t loss: 0.006\n",
      "i: 946, \t target: -0.875, \t output: -0.869, \t loss: 0.000\n",
      "i: 947, \t target: -0.569, \t output: -0.589, \t loss: 0.000\n",
      "i: 948, \t target: 0.999, \t output: 1.027, \t loss: 0.001\n",
      "i: 949, \t target: -1.008, \t output: -1.055, \t loss: 0.002\n",
      "i: 950, \t target: -0.800, \t output: -0.847, \t loss: 0.002\n",
      "i: 951, \t target: 3.135, \t output: 3.065, \t loss: 0.005\n",
      "i: 952, \t target: -0.699, \t output: -0.723, \t loss: 0.001\n",
      "i: 953, \t target: -0.748, \t output: -0.798, \t loss: 0.002\n",
      "i: 954, \t target: 2.071, \t output: 2.204, \t loss: 0.018\n",
      "i: 955, \t target: -0.927, \t output: -0.958, \t loss: 0.001\n",
      "i: 956, \t target: 1.105, \t output: 1.183, \t loss: 0.006\n",
      "i: 957, \t target: 1.355, \t output: 1.432, \t loss: 0.006\n",
      "i: 958, \t target: -1.159, \t output: -1.196, \t loss: 0.001\n",
      "i: 959, \t target: -0.322, \t output: -0.371, \t loss: 0.002\n",
      "i: 960, \t target: 0.357, \t output: 0.305, \t loss: 0.003\n",
      "i: 961, \t target: -0.173, \t output: -0.201, \t loss: 0.001\n",
      "i: 962, \t target: 1.861, \t output: 1.953, \t loss: 0.008\n",
      "i: 963, \t target: -0.395, \t output: -0.453, \t loss: 0.003\n",
      "i: 964, \t target: -0.489, \t output: -0.564, \t loss: 0.006\n",
      "i: 965, \t target: -0.810, \t output: -0.872, \t loss: 0.004\n",
      "i: 966, \t target: -0.983, \t output: -1.042, \t loss: 0.003\n",
      "i: 967, \t target: 0.659, \t output: 0.664, \t loss: 0.000\n",
      "i: 968, \t target: 1.455, \t output: 1.436, \t loss: 0.000\n",
      "i: 969, \t target: -0.648, \t output: -0.711, \t loss: 0.004\n",
      "i: 970, \t target: 2.523, \t output: 2.538, \t loss: 0.000\n",
      "i: 971, \t target: -0.737, \t output: -0.788, \t loss: 0.003\n",
      "i: 972, \t target: -0.354, \t output: -0.375, \t loss: 0.000\n",
      "i: 973, \t target: -0.803, \t output: -0.822, \t loss: 0.000\n",
      "i: 974, \t target: -0.912, \t output: -1.008, \t loss: 0.009\n",
      "i: 975, \t target: -0.911, \t output: -0.959, \t loss: 0.002\n",
      "i: 976, \t target: -0.919, \t output: -0.946, \t loss: 0.001\n",
      "i: 977, \t target: 1.017, \t output: 1.074, \t loss: 0.003\n",
      "i: 978, \t target: 0.408, \t output: 0.304, \t loss: 0.011\n",
      "i: 979, \t target: -0.908, \t output: -0.975, \t loss: 0.005\n",
      "i: 980, \t target: -0.717, \t output: -0.806, \t loss: 0.008\n",
      "i: 981, \t target: 1.472, \t output: 1.432, \t loss: 0.002\n",
      "i: 982, \t target: 3.610, \t output: 3.708, \t loss: 0.010\n",
      "i: 983, \t target: 0.444, \t output: 0.419, \t loss: 0.001\n",
      "i: 984, \t target: -0.892, \t output: -0.944, \t loss: 0.003\n",
      "i: 985, \t target: 3.091, \t output: 3.153, \t loss: 0.004\n",
      "i: 986, \t target: -0.665, \t output: -0.627, \t loss: 0.001\n",
      "i: 987, \t target: -0.587, \t output: -0.607, \t loss: 0.000\n",
      "i: 988, \t target: 2.087, \t output: 2.176, \t loss: 0.008\n",
      "i: 989, \t target: 1.895, \t output: 1.949, \t loss: 0.003\n",
      "i: 990, \t target: 1.993, \t output: 2.094, \t loss: 0.010\n",
      "i: 991, \t target: -0.439, \t output: -0.385, \t loss: 0.003\n",
      "i: 992, \t target: 3.421, \t output: 3.548, \t loss: 0.016\n",
      "i: 993, \t target: 1.424, \t output: 1.549, \t loss: 0.016\n",
      "i: 994, \t target: 2.010, \t output: 2.076, \t loss: 0.004\n",
      "i: 995, \t target: -0.699, \t output: -0.775, \t loss: 0.006\n",
      "i: 996, \t target: 1.811, \t output: 1.794, \t loss: 0.000\n",
      "i: 997, \t target: 3.036, \t output: 2.943, \t loss: 0.009\n",
      "i: 998, \t target: -0.794, \t output: -0.868, \t loss: 0.005\n",
      "i: 999, \t target: -0.741, \t output: -0.797, \t loss: 0.003\n",
      "Average loss: 0.005\n"
     ]
    }
   ],
   "source": [
    "avg_loss = 0\n",
    "for x, (i, t) in enumerate(zip((input_validation), target_validation)):\n",
    "    loss = criterion(model(i), t)\n",
    "    avg_loss += loss/len(target_validation)\n",
    "    print('i: {}, \\t target: {:.3f}, \\t output: {:.3f}, \\t loss: {:.3f}'.format(x, t.item(), model(i).item(), loss))\n",
    "\n",
    "print('Average loss: {:.3f}'.format(avg_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Notebook as a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['jupyter', 'nbconvert', '--to', 'pdf', '--output', 'here.pdf', '0728-small_hybrid_model_1q_measurement_v1.ipynb'], returncode=255)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "name_notebook = \"0728-small_hybrid_model_1q_measurement_v1.ipynb\"  \n",
    "\n",
    "output_filename = \"peptide-QML/Notebooks/results/\"+ name_notebook[:4] +\"/\" + name_notebook[:-6] + \"_0.pdf\"\n",
    "output_filename = \"here.pdf\"\n",
    "\n",
    "#check if the output file already exists\n",
    "while os.path.exists(output_filename):\n",
    "    print(\"The file {} already exists\".format(output_filename))\n",
    "    output_filename = output_filename[:-5] + str(int(output_filename[-5]) + 1) + \".pdf\"\n",
    "    print(\"Trying to save the file as {}\".format(output_filename))\n",
    "    \n",
    "\n",
    "subprocess.run([\"jupyter\", \"nbconvert\", \"--to\", \"pdf\", \"--output\", output_filename, name_notebook])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JL_Pennylane",
   "language": "python",
   "name": "jl_pennylane"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
