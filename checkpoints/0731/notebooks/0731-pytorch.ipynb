{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import torch\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 1: 0.5108\n",
      "Average loss over epoch 2: 0.5004\n",
      "Average loss over epoch 3: 0.5067\n",
      "Average loss over epoch 4: 0.5028\n",
      "Average loss over epoch 5: 0.5107\n",
      "Average loss over epoch 6: 0.5039\n",
      "Average loss over epoch 7: 0.5029\n",
      "Average loss over epoch 8: 0.5017\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 2\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits, shots=1000)\n",
    "\n",
    "@qml.qnode(dev, diff_method=\"spsa\", interface=\"torch\")\n",
    "def qnode(inputs, weights):\n",
    "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1))\n",
    "\n",
    "weight_shapes = {\"weights\": (3, n_qubits, 3)}\n",
    "\n",
    "\n",
    "\n",
    "class QNodeFunction(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, qlayer):\n",
    "        ctx.save_for_backward(input)\n",
    "        ctx.qlayer = qlayer\n",
    "        return qlayer(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        qlayer = ctx.qlayer\n",
    "        epsilon = 0.01\n",
    "        \n",
    "        # Gradient w.r.t. input\n",
    "        perturbation_input = (torch.rand_like(input) * 2 - 1) * epsilon\n",
    "        positive_input = input + perturbation_input\n",
    "        negative_input = input - perturbation_input\n",
    "        \n",
    "        loss_positive = qlayer(positive_input).sum()\n",
    "        loss_negative = qlayer(negative_input).sum()\n",
    "        \n",
    "        gradient_input = (loss_positive - loss_negative) / (2 * epsilon) * perturbation_input\n",
    "        gradient_input *= grad_output  # Incorporate grad_output due to chain rule\n",
    "\n",
    "        # Gradient w.r.t. qlayer's parameters\n",
    "        gradients_weights = []\n",
    "        for p in qlayer.parameters():\n",
    "            perturbation_weight = (torch.rand_like(p) * 2 - 1) * epsilon\n",
    "            p.data += perturbation_weight\n",
    "\n",
    "            loss_positive = qlayer(input).sum()\n",
    "            loss_negative = qlayer(input).sum()\n",
    "\n",
    "            gradient_weight = (loss_positive - loss_negative) / (2 * epsilon) * perturbation_weight / epsilon\n",
    "            gradients_weights.append(gradient_weight * grad_output.sum())  # Weighting by grad_output\n",
    "\n",
    "            p.data -= perturbation_weight  # Reset to original value\n",
    "\n",
    "        # Update gradients for qlayer's parameters\n",
    "        for p, grad in zip(qlayer.parameters(), gradients_weights):\n",
    "            if p.grad is None:\n",
    "                p.grad = grad.detach()\n",
    "            else:\n",
    "                p.grad += grad.detach()\n",
    "\n",
    "        return gradient_input, None\n",
    "\n",
    "# Wrapper around the custom autograd function\n",
    "class CustomQLayer(torch.nn.Module):\n",
    "    def __init__(self, qlayer):\n",
    "        super(CustomQLayer, self).__init__()\n",
    "        self.qlayer = qlayer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return QNodeFunction.apply(x, self.qlayer)\n",
    "\n",
    "\n",
    "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "clayer1 = torch.nn.Linear(2, 2)\n",
    "clayer2 = torch.nn.Linear(2, 2)\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "model = torch.nn.Sequential(clayer1, qlayer, clayer2, softmax)\n",
    "\n",
    "model[1] = CustomQLayer(qlayer)\n",
    "\n",
    "samples = 100\n",
    "x, y = sklearn.datasets.make_moons(samples)\n",
    "y_hot = np.zeros((samples, 2))\n",
    "y_hot[np.arange(samples), y] = 1\n",
    "\n",
    "X = torch.tensor(x, dtype=torch.float64)\n",
    "Y = torch.tensor(y_hot, dtype=torch.float64)\n",
    "\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "loss = torch.nn.L1Loss()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "for i in qlayer.parameters():\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 1: 0.4995\n",
      "Average loss over epoch 2: 0.4992\n",
      "Average loss over epoch 3: 0.5024\n",
      "Average loss over epoch 4: 0.5041\n",
      "Average loss over epoch 5: 0.5041\n",
      "Average loss over epoch 6: 0.4989\n",
      "Average loss over epoch 7: 0.4990\n",
      "Average loss over epoch 8: 0.5018\n"
     ]
    }
   ],
   "source": [
    "epochs = 8\n",
    "batch_size = 5\n",
    "batches = samples // batch_size\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(X, Y)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    for x, y in data_loader:\n",
    "        opt.zero_grad()\n",
    "\n",
    "        loss_evaluated = loss(model(x), y)\n",
    "        loss_evaluated.backward()\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss_evaluated\n",
    "\n",
    "    avg_loss = running_loss / batches\n",
    "    print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PennyLane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
