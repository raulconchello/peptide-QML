{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_path = 'peptide-QML'\n",
    "# initial_path = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, torch, copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "sys.path.append(initial_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from my_code import helper_classes as c\n",
    "from my_code import quantum_nodes as q\n",
    "from my_code.vae import VAE as VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScorePredictor(c.Module):\n",
    "    def __init__(self, latent_dim:int):\n",
    "        super(ScorePredictor, self).__init__()\n",
    "\n",
    "        # quantum circuit\n",
    "        quantum_circuit = q.circuit(\n",
    "            n_qubits = int(q.np.ceil(q.np.log2(latent_dim))),\n",
    "            device = \"default.qubit.torch\",\n",
    "            device_options = {'shots': None},\n",
    "            embedding = q.parts.AmplitudeEmbedding,\n",
    "            # embedding_ansatz = sweep_point['ansatz'],\n",
    "            block_ansatz = q.parts.Ansatz_11,\n",
    "            final_ansatz = q.parts.Ansatz_11, \n",
    "            measurement = q.parts.Measurement('Z', 1),\n",
    "            # embedding_n_layers = sweep_point['embedding_n_layers'],\n",
    "            # different_inputs_per_layer = False,\n",
    "            block_n_layers = 10,\n",
    "            # wrapper_qlayer = pw.QLayerEmpty,\n",
    "        )\n",
    "        self.quantum_descprition = str(quantum_circuit)\n",
    "\n",
    "        # layers of the model\n",
    "        self.quantum_layer = quantum_circuit()\n",
    "        self.post_quantum = nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.quantum_layer(x)\n",
    "        x = self.post_quantum(x)\n",
    "        x = x.squeeze(-1)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def loss_function(SP_out, batch, reduction:str='mean'):\n",
    "        x, y = batch\n",
    "        return F.mse_loss(SP_out, y.float(), reduction=reduction)\n",
    "    \n",
    "    def save(self, path):\n",
    "        copy_of_self = c.copy.deepcopy(self).to('cpu')\n",
    "        copy_of_self.quantum_layer = None\n",
    "        torch.save(copy_of_self, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "# load the vae and define the score predictor\n",
    "name = 'vae_TEST.pickle'\n",
    "vae_model = VAE.load(initial_path+'/saved/Pickle/VAE-'+name).to(device)\n",
    "score_predictor = ScorePredictor(latent_dim=vae_model.hyparams['latent_dim']).to(device)\n",
    "\n",
    "#data\n",
    "data = c.Data.load(initial_path=initial_path, file_name='PET_SCORES_12').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    }
   ],
   "source": [
    "# data_encoded = copy.deepcopy(data)\n",
    "# data_encoded.x_train = vae_model.encoder(data.x_train)[0]\n",
    "# data_encoded.x_test = vae_model.encoder(data.x_test)[0]\n",
    "\n",
    "data_encoded_noise = copy.deepcopy(data)\n",
    "data_encoded_noise.x_train = VAE.reparameterize(vae_model.encoder(data.x_train))\n",
    "data_encoded_noise.x_test = VAE.reparameterize(vae_model.encoder(data.x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = c.Optimizer(vae_model, torch.optim.Adam, {'lr': 3e-4})\n",
    "\n",
    "# training\n",
    "optimizer.optimize_parameters(\n",
    "    data=data_encoded_noise,\n",
    "    n_epochs=5,\n",
    "    batch_size=64,\n",
    "    validation=True,\n",
    "    save=True,\n",
    "    save_path=initial_path+'/saved/Pickle/SP-'+name,\n",
    "    test_ptc=0.1,\n",
    "    loss_fn_options={'reduction': 'sum'},\n",
    "    early_stopping_options={'patience': 5, 'min_delta': 0.001},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find vector in laten space that gives the lowest score\n",
    "n_sequences = 10\n",
    "latent_sequences, scores_predicted, sequences, scores = [], [], [], []\n",
    "for i in range(n_sequences):\n",
    "    vector = torch.randn(1, vae_model.hyparams['latent_dim'])\n",
    "    vector.requires_grad = True\n",
    "    optimizer = torch.optim.Adam([vector], lr=0.01)\n",
    "    for i in range(100):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        score_predicted = score_predictor(vector)\n",
    "        score_predicted.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch {i+1}/1000, score={score_predicted.item():.6f}                                                       ', end='\\r')\n",
    "\n",
    "        # early stopping\n",
    "        patience, min_delta = 10, 0.01\n",
    "        if i > patience:\n",
    "            score_difference = q.np.mean(score_predicted.item() - score_predicted.item()) - score_predicted.item()\n",
    "            if score_difference < min_delta:\n",
    "                print('Early stopping', end='\\r')\n",
    "                break\n",
    "    latent_sequences.append(vector)\n",
    "    scores_predicted.append(score_predicted.item())\n",
    "    sequences.append(vae_model.decoder(vector).tolist())\n",
    "    encoded_new_seq = torch.cat(list(vae_model.encoder(torch.tensor([sequences[-1]]))), dim=-1)\n",
    "    scores.append(score_predictor(encoded_new_seq).item())\n",
    "    print(f'sequence generated, score pred={score_predicted.item()}, real score={scores[-1].item()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sequence_decoded = vae_model.decoder(vector)\n",
    "print(new_sequence_decoded)\n",
    "new_sequence = vae_model.process_output(new_sequence_decoded)\n",
    "print(new_sequence)\n",
    "score_new_sequence = score_predictor(vae_model.encode(new_sequence)[0])\n",
    "print(score_new_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_w_ScorePredictor(c.Module):\n",
    "    def __init__(self, vae, score_predictor):\n",
    "        super(VAE_w_ScorePredictor, self).__init__()\n",
    "        self.vae = vae\n",
    "        self.score_predictor = score_predictor\n",
    "\n",
    "    def forward(self, x):\n",
    "        vae_out = self.vae(x)\n",
    "        score = self.score_predictor(self.vae.reparameterize(vae_out))\n",
    "        return vae_out, score\n",
    "    \n",
    "    @staticmethod\n",
    "    def loss_function(model_out, batch, **loss_fn_options):\n",
    "        vae_out, score = model_out\n",
    "        vae_loss = VAE.loss_function(vae_out, batch, **loss_fn_options)\n",
    "        score_loss = ScorePredictor.loss_function(score, batch, **loss_fn_options)\n",
    "        return vae_loss + score_loss\n",
    "    \n",
    "    validation_return = ['vae_loss', 'vae_acc', 'score_loss']\n",
    "    def validation(self, batch, loss_fn_options:dict={}):\n",
    "        x, y = batch\n",
    "        with torch.no_grad():\n",
    "            vae_out = self.vae(x)\n",
    "            vae_loss = VAE.loss_function(vae_out, batch, **loss_fn_options)\n",
    "\n",
    "            x_pred = VAE.process_output(self.decoder(vae_out[1]))\n",
    "            vae_acc = (x_pred == x).float().mean()\n",
    "\n",
    "            score = self.score_predictor(self.vae.reparameterize(vae_out))\n",
    "            score_loss = ScorePredictor.loss_function(score, batch, **loss_fn_options)\n",
    "        return vae_loss.item(), vae_acc.item(), score_loss.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JL_Pennylane",
   "language": "python",
   "name": "jl_pennylane"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
