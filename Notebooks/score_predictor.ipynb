{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_path = 'peptide-QML'\n",
    "# initial_path = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "sys.path.append(initial_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from my_code import helper_classes as c\n",
    "from my_code import quantum_nodes as q\n",
    "from my_code import vae.VAE as VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScorePredictor(c.Module):\n",
    "    def __init__(self, latent_dim:int):\n",
    "        super(ScorePredictor, self).__init__()\n",
    "\n",
    "        # quantum circuit\n",
    "        quantum_circuit = q.circuit(\n",
    "            n_qubits = int(q.np.ceil(q.np.log2(latent_dim))),\n",
    "            device = \"default.qubit.torch\",\n",
    "            device_options = {'shots': None},\n",
    "            embedding = q.parts.AmplitudeEmbedding,\n",
    "            # embedding_ansatz = sweep_point['ansatz'],\n",
    "            block_ansatz = q.parts.Ansatz_11,\n",
    "            final_ansatz = q.parts.Ansatz_11, \n",
    "            measurement = q.parts.Measurement('Z', 1),\n",
    "            # embedding_n_layers = sweep_point['embedding_n_layers'],\n",
    "            # different_inputs_per_layer = False,\n",
    "            block_n_layers = 10,\n",
    "            # wrapper_qlayer = pw.QLayerEmpty,\n",
    "        )\n",
    "        self.quantum_descprition = str(quantum_circuit)\n",
    "\n",
    "        # layers of the model\n",
    "        self.quantum_layer = quantum_circuit()\n",
    "        self.post_quantum = nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.quantum_layer(x)\n",
    "        x = self.post_quantum(x)\n",
    "        x = x.squeeze(-1)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def loss_function(SP_out, batch, reduction:str='mean'):\n",
    "        x, y = batch\n",
    "        return F.mse_loss(SP_out, y.float(), reduction=reduction)\n",
    "    \n",
    "    def save(self, path):\n",
    "        copy_of_self = c.copy.deepcopy(self).to('cpu')\n",
    "        copy_of_self.quantum_layer = None\n",
    "        torch.save(copy_of_self, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'vae_TEST.pickle'\n",
    "vae_model = VAE.load(initial_path+'/saved/Pickle/VAE-'name)\n",
    "score_predictor = ScorePredictor(latent_dim=vae_model.latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP = ScorePredictor(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JL_Pennylane",
   "language": "python",
   "name": "jl_pennylane"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
